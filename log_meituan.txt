INFO:root:21:09:32 Namespace(accumulate=None, batch_size=1, bert_dataset='wiki_cn_cased', bert_model='bert_12_768_12', calib_mode='customize', deploy=False, dev_batch_size=8, dtype='float32', early_stop=None, epochs=5, epsilon=1e-06, gpu=0, log_interval=40, lr=2e-05, max_len=128, model_parameters=None, model_prefix=None, num_calib_batches=5, only_calibration=False, only_inference=False, optimizer='bertadam', output_dir='./output_dir', pretrained_bert_parameters=None, quantized_dtype='auto', round_to=None, seed=2, task_name='meituan', training_steps=None, warmup_ratio=0.1)
INFO:root:21:09:48 Namespace(accumulate=None, batch_size=1, bert_dataset='wiki_cn_cased', bert_model='bert_12_768_12', calib_mode='customize', deploy=False, dev_batch_size=8, dtype='float32', early_stop=None, epochs=5, epsilon=1e-06, gpu=0, log_interval=40, lr=2e-05, max_len=128, model_parameters=None, model_prefix=None, num_calib_batches=5, only_calibration=False, only_inference=False, optimizer='bertadam', output_dir='./output_dir', pretrained_bert_parameters=None, quantized_dtype='auto', round_to=None, seed=2, task_name='meituan', training_steps=None, warmup_ratio=0.1)
INFO:root:21:10:02 processing dataset...
INFO:root:21:10:40 Namespace(accumulate=None, batch_size=1, bert_dataset='wiki_cn_cased', bert_model='bert_12_768_12', calib_mode='customize', deploy=False, dev_batch_size=8, dtype='float32', early_stop=None, epochs=5, epsilon=1e-06, gpu=0, log_interval=40, lr=2e-05, max_len=128, model_parameters=None, model_prefix=None, num_calib_batches=5, only_calibration=False, only_inference=False, optimizer='bertadam', output_dir='./output_dir', pretrained_bert_parameters=None, quantized_dtype='auto', round_to=None, seed=2, task_name='meituan', training_steps=None, warmup_ratio=0.1)
INFO:root:21:10:48 processing dataset...
INFO:root:21:17:01 Namespace(accumulate=None, batch_size=1, bert_dataset='wiki_cn_cased', bert_model='bert_12_768_12', calib_mode='customize', deploy=False, dev_batch_size=8, dtype='float32', early_stop=None, epochs=5, epsilon=1e-06, gpu=0, log_interval=40, lr=2e-05, max_len=128, model_parameters=None, model_prefix=None, num_calib_batches=5, only_calibration=False, only_inference=False, optimizer='bertadam', output_dir='./output_dir', pretrained_bert_parameters=None, quantized_dtype='auto', round_to=None, seed=2, task_name='meituan', training_steps=None, warmup_ratio=0.1)
INFO:root:21:17:08 processing dataset...
INFO:root:21:17:53 Now we are doing BERT classification training on gpu(0)!
INFO:root:21:17:54 training steps=184250
INFO:root:21:17:59 [Epoch 1 Batch 40/36850] loss=1.7854, lr=0.0000000, metrics:accuracy:0.1000
INFO:root:21:18:01 [Epoch 1 Batch 80/36850] loss=1.6885, lr=0.0000001, metrics:accuracy:0.1250
INFO:root:21:18:03 [Epoch 1 Batch 120/36850] loss=1.5670, lr=0.0000001, metrics:accuracy:0.1583
INFO:root:21:18:07 [Epoch 1 Batch 160/36850] loss=1.5442, lr=0.0000002, metrics:accuracy:0.1688
INFO:root:21:18:09 [Epoch 1 Batch 200/36850] loss=1.4171, lr=0.0000002, metrics:accuracy:0.2200
INFO:root:21:18:11 [Epoch 1 Batch 240/36850] loss=1.2823, lr=0.0000003, metrics:accuracy:0.2375
INFO:root:21:18:14 [Epoch 1 Batch 280/36850] loss=1.2982, lr=0.0000003, metrics:accuracy:0.2571
INFO:root:21:18:17 [Epoch 1 Batch 320/36850] loss=1.4904, lr=0.0000003, metrics:accuracy:0.2719
INFO:root:21:18:19 [Epoch 1 Batch 360/36850] loss=1.2865, lr=0.0000004, metrics:accuracy:0.3028
INFO:root:21:18:22 [Epoch 1 Batch 400/36850] loss=1.0580, lr=0.0000004, metrics:accuracy:0.3275
INFO:root:21:18:25 [Epoch 1 Batch 440/36850] loss=1.2042, lr=0.0000005, metrics:accuracy:0.3432
INFO:root:21:18:26 [Epoch 1 Batch 480/36850] loss=1.2801, lr=0.0000005, metrics:accuracy:0.3458
INFO:root:21:29:16 Namespace(accumulate=None, batch_size=1, bert_dataset='wiki_cn_cased', bert_model='bert_12_768_12', calib_mode='customize', deploy=False, dev_batch_size=8, dtype='float32', early_stop=None, epochs=5, epsilon=1e-06, gpu=0, log_interval=40, lr=2e-05, max_len=128, model_parameters=None, model_prefix=None, num_calib_batches=5, only_calibration=False, only_inference=False, optimizer='bertadam', output_dir='./output_dir', pretrained_bert_parameters=None, quantized_dtype='auto', round_to=None, seed=2, task_name='meituan', training_steps=None, warmup_ratio=0.1)
INFO:root:21:29:20 processing dataset...
INFO:root:21:29:51 Now we are doing BERT classification training on gpu(0)!
INFO:root:21:29:51 training steps=184250
INFO:root:21:29:52 Now we are doing evaluation on dev with gpu(0).
INFO:root:21:29:53 [Batch 40/618] loss=1.6584, metrics:accuracy:0.1313
INFO:root:21:29:54 [Batch 80/618] loss=1.6934, metrics:accuracy:0.1156
INFO:root:21:29:55 [Batch 120/618] loss=1.6439, metrics:accuracy:0.1281
INFO:root:21:29:57 [Batch 160/618] loss=1.7014, metrics:accuracy:0.1164
INFO:root:21:29:58 [Batch 200/618] loss=1.6384, metrics:accuracy:0.1200
INFO:root:21:29:59 [Batch 240/618] loss=1.6818, metrics:accuracy:0.1203
INFO:root:21:30:00 [Batch 280/618] loss=1.6528, metrics:accuracy:0.1250
INFO:root:21:30:01 [Batch 320/618] loss=1.6449, metrics:accuracy:0.1242
INFO:root:21:30:02 [Batch 360/618] loss=1.6910, metrics:accuracy:0.1219
INFO:root:21:30:04 [Batch 400/618] loss=1.6372, metrics:accuracy:0.1259
INFO:root:21:30:05 [Batch 440/618] loss=1.6128, metrics:accuracy:0.1267
INFO:root:21:30:06 [Batch 480/618] loss=1.6439, metrics:accuracy:0.1268
INFO:root:21:30:07 [Batch 520/618] loss=1.6391, metrics:accuracy:0.1291
INFO:root:21:30:08 [Batch 560/618] loss=1.6674, metrics:accuracy:0.1277
INFO:root:21:30:10 [Batch 600/618] loss=1.6304, metrics:accuracy:0.1271
INFO:root:21:30:10 validation metrics:accuracy:0.1259
INFO:root:21:30:10 Time cost=18.06s, throughput=273.79 samples/s
INFO:root:21:30:11 params saved in: ./output_dir/model_bert_meituan_0.params
INFO:root:21:30:11 Time cost=19.73s
INFO:root:21:30:11 Now we are doing evaluation on dev with gpu(0).
INFO:root:21:30:12 [Batch 40/618] loss=1.6583, metrics:accuracy:0.1313
INFO:root:21:30:13 [Batch 80/618] loss=1.6934, metrics:accuracy:0.1156
INFO:root:21:30:14 [Batch 120/618] loss=1.6439, metrics:accuracy:0.1281
INFO:root:21:30:15 [Batch 160/618] loss=1.7014, metrics:accuracy:0.1164
INFO:root:21:30:17 [Batch 200/618] loss=1.6383, metrics:accuracy:0.1200
INFO:root:21:30:18 [Batch 240/618] loss=1.6818, metrics:accuracy:0.1203
INFO:root:21:37:26 Namespace(accumulate=None, batch_size=1, bert_dataset='wiki_cn_cased', bert_model='bert_12_768_12', calib_mode='customize', deploy=False, dev_batch_size=8, dtype='float32', early_stop=None, epochs=5, epsilon=1e-06, gpu=0, log_interval=40, lr=2e-05, max_len=128, model_parameters=None, model_prefix=None, num_calib_batches=5, only_calibration=False, only_inference=False, optimizer='bertadam', output_dir='./output_dir', pretrained_bert_parameters=None, quantized_dtype='auto', round_to=None, seed=2, task_name='meituan', training_steps=None, warmup_ratio=0.1)
INFO:root:21:37:30 processing dataset...
INFO:root:21:38:00 Now we are doing BERT classification training on gpu(0)!
INFO:root:21:38:00 training steps=184250
INFO:root:21:38:01 Now we are doing evaluation on dev with gpu(0).
INFO:root:21:38:02 [Batch 40/618] loss=1.6584, metrics:accuracy:0.1313
INFO:root:21:38:03 [Batch 80/618] loss=1.6934, metrics:accuracy:0.1156
INFO:root:21:40:57 Namespace(accumulate=None, batch_size=1, bert_dataset='wiki_cn_cased', bert_model='bert_12_768_12', calib_mode='customize', deploy=False, dev_batch_size=8, dtype='float32', early_stop=None, epochs=5, epsilon=1e-06, gpu=0, log_interval=40, lr=2e-05, max_len=128, model_parameters=None, model_prefix=None, num_calib_batches=5, only_calibration=False, only_inference=False, optimizer='bertadam', output_dir='./output_dir', pretrained_bert_parameters=None, quantized_dtype='auto', round_to=None, seed=2, task_name='meituan', training_steps=None, warmup_ratio=0.1)
INFO:root:21:41:02 processing dataset...
INFO:root:21:41:33 Now we are doing BERT classification training on gpu(0)!
INFO:root:21:41:33 training steps=184250
INFO:root:21:41:35 [Epoch 1 Batch 40/36850] loss=1.7854, lr=0.0000000, metrics:accuracy:0.1000
INFO:root:21:41:37 [Epoch 1 Batch 80/36850] loss=1.6885, lr=0.0000001, metrics:accuracy:0.1250
INFO:root:21:41:39 [Epoch 1 Batch 120/36850] loss=1.5670, lr=0.0000001, metrics:accuracy:0.1583
INFO:root:21:41:40 [Epoch 1 Batch 160/36850] loss=1.5442, lr=0.0000002, metrics:accuracy:0.1688
INFO:root:21:41:42 [Epoch 1 Batch 200/36850] loss=1.4171, lr=0.0000002, metrics:accuracy:0.2200
INFO:root:21:41:53 Namespace(accumulate=None, batch_size=1, bert_dataset='wiki_cn_cased', bert_model='bert_12_768_12', calib_mode='customize', deploy=False, dev_batch_size=8, dtype='float32', early_stop=None, epochs=5, epsilon=1e-06, gpu=0, log_interval=40, lr=2e-05, max_len=128, model_parameters=None, model_prefix=None, num_calib_batches=5, only_calibration=False, only_inference=False, optimizer='bertadam', output_dir='./output_dir', pretrained_bert_parameters=None, quantized_dtype='auto', round_to=None, seed=2, task_name='meituan', training_steps=None, warmup_ratio=0.1)
INFO:root:21:41:58 processing dataset...
INFO:root:21:42:26 Now we are doing BERT classification training on gpu(0)!
INFO:root:21:42:26 training steps=184250
INFO:root:21:42:27 Now we are doing evaluation on dev with gpu(0).
INFO:root:21:42:28 [Batch 40/618] loss=1.6584, metrics:accuracy:0.1313
INFO:root:21:42:29 [Batch 80/618] loss=1.6934, metrics:accuracy:0.1156
INFO:root:21:42:30 [Batch 120/618] loss=1.6439, metrics:accuracy:0.1281
INFO:root:21:42:32 [Batch 160/618] loss=1.7014, metrics:accuracy:0.1164
INFO:root:21:42:33 [Batch 200/618] loss=1.6384, metrics:accuracy:0.1200
INFO:root:21:42:34 [Batch 240/618] loss=1.6818, metrics:accuracy:0.1203
INFO:root:21:42:35 [Batch 280/618] loss=1.6528, metrics:accuracy:0.1250
INFO:root:21:42:36 [Batch 320/618] loss=1.6449, metrics:accuracy:0.1242
INFO:root:21:42:37 [Batch 360/618] loss=1.6910, metrics:accuracy:0.1219
INFO:root:21:42:38 [Batch 400/618] loss=1.6372, metrics:accuracy:0.1259
INFO:root:21:42:40 [Batch 440/618] loss=1.6128, metrics:accuracy:0.1267
INFO:root:21:42:41 [Batch 480/618] loss=1.6439, metrics:accuracy:0.1268
INFO:root:21:42:42 [Batch 520/618] loss=1.6391, metrics:accuracy:0.1291
INFO:root:21:42:43 [Batch 560/618] loss=1.6674, metrics:accuracy:0.1277
INFO:root:21:44:13 Namespace(accumulate=None, batch_size=1, bert_dataset='wiki_cn_cased', bert_model='bert_12_768_12', calib_mode='customize', deploy=False, dev_batch_size=8, dtype='float32', early_stop=None, epochs=5, epsilon=1e-06, gpu=0, log_interval=40, lr=2e-05, max_len=128, model_parameters=None, model_prefix=None, num_calib_batches=5, only_calibration=False, only_inference=False, optimizer='bertadam', output_dir='./output_dir', pretrained_bert_parameters=None, quantized_dtype='auto', round_to=None, seed=2, task_name='meituan', training_steps=None, warmup_ratio=0.1)
INFO:root:21:44:18 processing dataset...
INFO:root:21:44:47 Now we are doing BERT classification training on gpu(0)!
INFO:root:21:44:47 training steps=184250
INFO:root:21:44:48 Now we are doing evaluation on dev with gpu(0).
INFO:root:21:44:49 [Batch 40/618] loss=1.6584, metrics:accuracy:0.1313
INFO:root:21:44:50 [Batch 80/618] loss=1.6934, metrics:accuracy:0.1156
INFO:root:21:44:51 [Batch 120/618] loss=1.6439, metrics:accuracy:0.1281
INFO:root:21:44:52 [Batch 160/618] loss=1.7014, metrics:accuracy:0.1164
INFO:root:21:44:53 [Batch 200/618] loss=1.6384, metrics:accuracy:0.1200
INFO:root:21:44:54 [Batch 240/618] loss=1.6818, metrics:accuracy:0.1203
INFO:root:21:44:55 [Batch 280/618] loss=1.6528, metrics:accuracy:0.1250
INFO:root:21:44:56 [Batch 320/618] loss=1.6449, metrics:accuracy:0.1242
INFO:root:21:44:58 [Batch 360/618] loss=1.6910, metrics:accuracy:0.1219
INFO:root:21:44:59 [Batch 400/618] loss=1.6372, metrics:accuracy:0.1259
INFO:root:21:45:00 [Batch 440/618] loss=1.6128, metrics:accuracy:0.1267
INFO:root:21:45:01 [Batch 480/618] loss=1.6439, metrics:accuracy:0.1268
INFO:root:21:45:02 [Batch 520/618] loss=1.6391, metrics:accuracy:0.1291
INFO:root:21:45:03 [Batch 560/618] loss=1.6674, metrics:accuracy:0.1277
INFO:root:21:45:04 [Batch 600/618] loss=1.6304, metrics:accuracy:0.1271
INFO:root:21:45:34 Namespace(accumulate=None, batch_size=1, bert_dataset='wiki_cn_cased', bert_model='bert_12_768_12', calib_mode='customize', deploy=False, dev_batch_size=8, dtype='float32', early_stop=None, epochs=5, epsilon=1e-06, gpu=0, log_interval=40, lr=2e-05, max_len=128, model_parameters=None, model_prefix=None, num_calib_batches=5, only_calibration=False, only_inference=False, optimizer='bertadam', output_dir='./output_dir', pretrained_bert_parameters=None, quantized_dtype='auto', round_to=None, seed=2, task_name='meituan', training_steps=None, warmup_ratio=0.1)
INFO:root:21:45:39 processing dataset...
INFO:root:21:46:09 Now we are doing BERT classification training on gpu(0)!
INFO:root:21:46:09 training steps=184250
INFO:root:21:46:10 Now we are doing evaluation on dev with gpu(0).
INFO:root:21:46:11 [Batch 40/618] loss=1.6584, metrics:accuracy:0.1313
INFO:root:21:46:12 [Batch 80/618] loss=1.6934, metrics:accuracy:0.1156
INFO:root:21:46:13 [Batch 120/618] loss=1.6439, metrics:accuracy:0.1281
INFO:root:21:46:14 [Batch 160/618] loss=1.7014, metrics:accuracy:0.1164
INFO:root:21:46:15 [Batch 200/618] loss=1.6384, metrics:accuracy:0.1200
INFO:root:21:46:16 [Batch 240/618] loss=1.6818, metrics:accuracy:0.1203
INFO:root:21:46:17 [Batch 280/618] loss=1.6528, metrics:accuracy:0.1250
INFO:root:21:46:19 [Batch 320/618] loss=1.6449, metrics:accuracy:0.1242
INFO:root:21:46:20 [Batch 360/618] loss=1.6910, metrics:accuracy:0.1219
INFO:root:21:46:21 [Batch 400/618] loss=1.6372, metrics:accuracy:0.1259
INFO:root:21:46:22 [Batch 440/618] loss=1.6128, metrics:accuracy:0.1267
INFO:root:21:46:23 [Batch 480/618] loss=1.6439, metrics:accuracy:0.1268
INFO:root:21:46:24 [Batch 520/618] loss=1.6391, metrics:accuracy:0.1291
INFO:root:21:46:25 [Batch 560/618] loss=1.6674, metrics:accuracy:0.1277
INFO:root:21:46:26 [Batch 600/618] loss=1.6304, metrics:accuracy:0.1271
INFO:root:21:47:03 Namespace(accumulate=None, batch_size=1, bert_dataset='wiki_cn_cased', bert_model='bert_12_768_12', calib_mode='customize', deploy=False, dev_batch_size=8, dtype='float32', early_stop=None, epochs=5, epsilon=1e-06, gpu=0, log_interval=40, lr=2e-05, max_len=128, model_parameters=None, model_prefix=None, num_calib_batches=5, only_calibration=False, only_inference=False, optimizer='bertadam', output_dir='./output_dir', pretrained_bert_parameters=None, quantized_dtype='auto', round_to=None, seed=2, task_name='meituan', training_steps=None, warmup_ratio=0.1)
INFO:root:21:47:07 processing dataset...
INFO:root:21:47:38 Now we are doing BERT classification training on gpu(0)!
INFO:root:21:47:38 training steps=184250
INFO:root:21:47:39 Now we are doing evaluation on dev with gpu(0).
INFO:root:21:47:40 [Batch 40/618] loss=1.6584, metrics:accuracy:0.1313
INFO:root:21:47:41 [Batch 80/618] loss=1.6934, metrics:accuracy:0.1156
INFO:root:21:47:42 [Batch 120/618] loss=1.6439, metrics:accuracy:0.1281
INFO:root:21:47:43 [Batch 160/618] loss=1.7014, metrics:accuracy:0.1164
INFO:root:21:47:44 [Batch 200/618] loss=1.6384, metrics:accuracy:0.1200
INFO:root:21:47:45 [Batch 240/618] loss=1.6818, metrics:accuracy:0.1203
INFO:root:21:47:46 [Batch 280/618] loss=1.6528, metrics:accuracy:0.1250
INFO:root:21:47:48 [Batch 320/618] loss=1.6449, metrics:accuracy:0.1242
INFO:root:21:47:49 [Batch 360/618] loss=1.6910, metrics:accuracy:0.1219
INFO:root:21:47:50 [Batch 400/618] loss=1.6372, metrics:accuracy:0.1259
INFO:root:21:47:51 [Batch 440/618] loss=1.6128, metrics:accuracy:0.1267
INFO:root:21:47:52 [Batch 480/618] loss=1.6439, metrics:accuracy:0.1268
INFO:root:21:47:53 [Batch 520/618] loss=1.6391, metrics:accuracy:0.1291
INFO:root:21:47:54 [Batch 560/618] loss=1.6674, metrics:accuracy:0.1277
INFO:root:21:47:55 [Batch 600/618] loss=1.6304, metrics:accuracy:0.1271
INFO:root:21:47:56 validation metrics:accuracy:0.1259
INFO:root:21:47:56 Time cost=17.20s, throughput=287.51 samples/s
INFO:root:21:47:57 params saved in: ./output_dir/model_bert_meituan_0.params
INFO:root:21:47:57 Time cost=19.20s
INFO:root:21:47:57 Now we are doing evaluation on dev with gpu(0).
INFO:root:21:47:58 [Batch 40/618] loss=1.6583, metrics:accuracy:0.1313
INFO:root:21:47:59 [Batch 80/618] loss=1.6934, metrics:accuracy:0.1156
INFO:root:21:48:01 [Batch 120/618] loss=1.6439, metrics:accuracy:0.1281
INFO:root:21:48:02 [Batch 160/618] loss=1.7014, metrics:accuracy:0.1164
INFO:root:21:48:03 [Batch 200/618] loss=1.6383, metrics:accuracy:0.1200
INFO:root:21:48:04 [Batch 240/618] loss=1.6818, metrics:accuracy:0.1203
INFO:root:21:48:05 [Batch 280/618] loss=1.6528, metrics:accuracy:0.1250
INFO:root:21:48:06 [Batch 320/618] loss=1.6449, metrics:accuracy:0.1242
INFO:root:21:48:07 [Batch 360/618] loss=1.6910, metrics:accuracy:0.1219
INFO:root:21:48:09 [Batch 400/618] loss=1.6372, metrics:accuracy:0.1259
INFO:root:21:48:10 [Batch 440/618] loss=1.6128, metrics:accuracy:0.1267
INFO:root:21:48:11 [Batch 480/618] loss=1.6439, metrics:accuracy:0.1268
INFO:root:21:48:12 [Batch 520/618] loss=1.6391, metrics:accuracy:0.1291
INFO:root:21:48:13 [Batch 560/618] loss=1.6674, metrics:accuracy:0.1277
INFO:root:21:48:14 [Batch 600/618] loss=1.6304, metrics:accuracy:0.1271
INFO:root:21:48:14 validation metrics:accuracy:0.1259
INFO:root:21:48:14 Time cost=17.20s, throughput=287.52 samples/s
INFO:root:21:48:15 params saved in: ./output_dir/model_bert_meituan_1.params
INFO:root:21:48:15 Time cost=17.90s
INFO:root:21:48:15 Now we are doing evaluation on dev with gpu(0).
INFO:root:21:48:17 [Batch 40/618] loss=1.6583, metrics:accuracy:0.1313
INFO:root:21:48:18 [Batch 80/618] loss=1.6933, metrics:accuracy:0.1156
INFO:root:21:48:19 [Batch 120/618] loss=1.6438, metrics:accuracy:0.1281
INFO:root:21:48:20 [Batch 160/618] loss=1.7014, metrics:accuracy:0.1164
INFO:root:21:48:21 [Batch 200/618] loss=1.6383, metrics:accuracy:0.1200
INFO:root:21:48:22 [Batch 240/618] loss=1.6817, metrics:accuracy:0.1203
INFO:root:21:48:24 [Batch 280/618] loss=1.6527, metrics:accuracy:0.1250
INFO:root:21:48:26 [Batch 320/618] loss=1.6449, metrics:accuracy:0.1242
INFO:root:21:48:27 [Batch 360/618] loss=1.6909, metrics:accuracy:0.1219
INFO:root:21:48:28 [Batch 400/618] loss=1.6371, metrics:accuracy:0.1259
INFO:root:21:48:29 [Batch 440/618] loss=1.6127, metrics:accuracy:0.1267
INFO:root:21:48:30 [Batch 480/618] loss=1.6438, metrics:accuracy:0.1268
INFO:root:21:48:31 [Batch 520/618] loss=1.6390, metrics:accuracy:0.1291
INFO:root:21:48:32 [Batch 560/618] loss=1.6673, metrics:accuracy:0.1277
INFO:root:21:48:33 [Batch 600/618] loss=1.6304, metrics:accuracy:0.1271
INFO:root:21:48:34 validation metrics:accuracy:0.1259
INFO:root:21:48:34 Time cost=18.69s, throughput=264.46 samples/s
INFO:root:21:48:34 params saved in: ./output_dir/model_bert_meituan_2.params
INFO:root:21:48:34 Time cost=19.42s
INFO:root:21:48:35 Now we are doing evaluation on dev with gpu(0).
INFO:root:21:48:36 [Batch 40/618] loss=1.6582, metrics:accuracy:0.1313
INFO:root:21:48:37 [Batch 80/618] loss=1.6932, metrics:accuracy:0.1156
INFO:root:21:48:38 [Batch 120/618] loss=1.6437, metrics:accuracy:0.1281
INFO:root:21:48:39 [Batch 160/618] loss=1.7013, metrics:accuracy:0.1164
INFO:root:21:48:40 [Batch 200/618] loss=1.6382, metrics:accuracy:0.1200
INFO:root:21:48:42 [Batch 240/618] loss=1.6816, metrics:accuracy:0.1203
INFO:root:21:48:43 [Batch 280/618] loss=1.6526, metrics:accuracy:0.1250
INFO:root:21:48:44 [Batch 320/618] loss=1.6447, metrics:accuracy:0.1242
INFO:root:21:48:45 [Batch 360/618] loss=1.6908, metrics:accuracy:0.1219
INFO:root:21:48:46 [Batch 400/618] loss=1.6370, metrics:accuracy:0.1259
INFO:root:21:48:47 [Batch 440/618] loss=1.6126, metrics:accuracy:0.1267
INFO:root:21:48:48 [Batch 480/618] loss=1.6437, metrics:accuracy:0.1268
INFO:root:21:48:49 [Batch 520/618] loss=1.6389, metrics:accuracy:0.1291
INFO:root:21:48:50 [Batch 560/618] loss=1.6672, metrics:accuracy:0.1277
INFO:root:21:48:52 [Batch 600/618] loss=1.6302, metrics:accuracy:0.1271
INFO:root:21:48:52 validation metrics:accuracy:0.1259
INFO:root:21:48:52 Time cost=17.46s, throughput=283.15 samples/s
INFO:root:21:48:53 params saved in: ./output_dir/model_bert_meituan_3.params
INFO:root:21:48:53 Time cost=18.19s
INFO:root:21:48:53 Now we are doing evaluation on dev with gpu(0).
INFO:root:21:48:54 [Batch 40/618] loss=1.6580, metrics:accuracy:0.1344
INFO:root:21:48:55 [Batch 80/618] loss=1.6930, metrics:accuracy:0.1172
INFO:root:21:48:56 [Batch 120/618] loss=1.6435, metrics:accuracy:0.1302
INFO:root:21:48:57 [Batch 160/618] loss=1.7011, metrics:accuracy:0.1180
INFO:root:21:48:58 [Batch 200/618] loss=1.6380, metrics:accuracy:0.1212
INFO:root:21:48:59 [Batch 240/618] loss=1.6814, metrics:accuracy:0.1214
INFO:root:21:49:01 [Batch 280/618] loss=1.6524, metrics:accuracy:0.1259
INFO:root:21:49:02 [Batch 320/618] loss=1.6446, metrics:accuracy:0.1250
INFO:root:21:49:03 [Batch 360/618] loss=1.6906, metrics:accuracy:0.1226
INFO:root:21:49:04 [Batch 400/618] loss=1.6369, metrics:accuracy:0.1266
INFO:root:21:49:05 [Batch 440/618] loss=1.6125, metrics:accuracy:0.1273
INFO:root:21:49:06 [Batch 480/618] loss=1.6435, metrics:accuracy:0.1273
INFO:root:21:49:07 [Batch 520/618] loss=1.6387, metrics:accuracy:0.1300
INFO:root:21:49:08 [Batch 560/618] loss=1.6670, metrics:accuracy:0.1286
INFO:root:21:49:09 [Batch 600/618] loss=1.6301, metrics:accuracy:0.1279
INFO:root:21:49:10 validation metrics:accuracy:0.1267
INFO:root:21:49:10 Time cost=17.19s, throughput=287.62 samples/s
INFO:root:21:49:11 params saved in: ./output_dir/model_bert_meituan_4.params
INFO:root:21:49:11 Time cost=17.88s
INFO:root:21:49:11 Best model at epoch 4. Validation metrics:accuracy:0.1267
INFO:root:21:49:11 Now we are doing testing on test with gpu(0).
INFO:root:21:49:28 Time cost=17.39s, throughput=284.30 samples/s
INFO:root:21:51:08 Namespace(accumulate=None, batch_size=32, bert_dataset='wiki_cn_cased', bert_model='bert_12_768_12', calib_mode='customize', deploy=False, dev_batch_size=8, dtype='float32', early_stop=None, epochs=5, epsilon=1e-06, gpu=0, log_interval=40, lr=2e-05, max_len=128, model_parameters=None, model_prefix=None, num_calib_batches=5, only_calibration=False, only_inference=False, optimizer='bertadam', output_dir='./output_dir', pretrained_bert_parameters=None, quantized_dtype='auto', round_to=None, seed=2, task_name='meituan', training_steps=None, warmup_ratio=0.1)
INFO:root:21:51:13 processing dataset...
INFO:root:21:51:43 Now we are doing BERT classification training on gpu(0)!
INFO:root:21:51:43 training steps=5757
INFO:root:21:58:38 Namespace(accumulate=2, batch_size=16, bert_dataset='wiki_cn_cased', bert_model='bert_12_768_12', calib_mode='customize', deploy=False, dev_batch_size=8, dtype='float32', early_stop=None, epochs=5, epsilon=1e-06, gpu=0, log_interval=40, lr=2e-05, max_len=128, model_parameters=None, model_prefix=None, num_calib_batches=5, only_calibration=False, only_inference=False, optimizer='bertadam', output_dir='./output_dir', pretrained_bert_parameters=None, quantized_dtype='auto', round_to=None, seed=2, task_name='meituan', training_steps=None, warmup_ratio=0.1)
INFO:root:21:58:38 Using gradient accumulation. Effective batch size = batch_size * accumulate = 32
INFO:root:21:58:42 processing dataset...
INFO:root:21:59:11 Now we are doing BERT classification training on gpu(0)!
INFO:root:21:59:11 training steps=5757
INFO:root:22:00:07 Namespace(accumulate=4, batch_size=8, bert_dataset='wiki_cn_cased', bert_model='bert_12_768_12', calib_mode='customize', deploy=False, dev_batch_size=8, dtype='float32', early_stop=None, epochs=5, epsilon=1e-06, gpu=0, log_interval=40, lr=2e-05, max_len=128, model_parameters=None, model_prefix=None, num_calib_batches=5, only_calibration=False, only_inference=False, optimizer='bertadam', output_dir='./output_dir', pretrained_bert_parameters=None, quantized_dtype='auto', round_to=None, seed=2, task_name='meituan', training_steps=None, warmup_ratio=0.1)
INFO:root:22:00:07 Using gradient accumulation. Effective batch size = batch_size * accumulate = 32
INFO:root:22:00:12 processing dataset...
INFO:root:22:00:42 Now we are doing BERT classification training on gpu(0)!
INFO:root:22:00:42 training steps=5757
INFO:root:22:00:46 [Epoch 1 Batch 40/4610] loss=1.6112, lr=0.0000003, metrics:accuracy:0.1844
INFO:root:22:00:48 [Epoch 1 Batch 80/4610] loss=1.4605, lr=0.0000007, metrics:accuracy:0.2687
INFO:root:22:00:51 [Epoch 1 Batch 120/4610] loss=1.2907, lr=0.0000010, metrics:accuracy:0.3211
INFO:root:22:00:54 [Epoch 1 Batch 160/4610] loss=1.2375, lr=0.0000014, metrics:accuracy:0.3456
INFO:root:22:00:57 [Epoch 1 Batch 200/4610] loss=1.2292, lr=0.0000017, metrics:accuracy:0.3553
INFO:root:22:01:00 [Epoch 1 Batch 240/4610] loss=1.2565, lr=0.0000021, metrics:accuracy:0.3634
INFO:root:22:01:02 [Epoch 1 Batch 280/4610] loss=1.2584, lr=0.0000024, metrics:accuracy:0.3736
INFO:root:22:01:05 [Epoch 1 Batch 320/4610] loss=1.2088, lr=0.0000027, metrics:accuracy:0.3847
INFO:root:22:01:08 [Epoch 1 Batch 360/4610] loss=1.2260, lr=0.0000031, metrics:accuracy:0.3934
INFO:root:22:01:11 [Epoch 1 Batch 400/4610] loss=1.2122, lr=0.0000034, metrics:accuracy:0.4016
INFO:root:22:01:14 [Epoch 1 Batch 440/4610] loss=1.1815, lr=0.0000038, metrics:accuracy:0.4093
INFO:root:22:01:16 [Epoch 1 Batch 480/4610] loss=1.1230, lr=0.0000041, metrics:accuracy:0.4184
INFO:root:22:01:19 [Epoch 1 Batch 520/4610] loss=1.2314, lr=0.0000045, metrics:accuracy:0.4174
INFO:root:22:01:22 [Epoch 1 Batch 560/4610] loss=1.1291, lr=0.0000048, metrics:accuracy:0.4218
INFO:root:22:01:25 [Epoch 1 Batch 600/4610] loss=1.0854, lr=0.0000052, metrics:accuracy:0.4273
INFO:root:22:01:28 [Epoch 1 Batch 640/4610] loss=1.1076, lr=0.0000055, metrics:accuracy:0.4327
INFO:root:22:01:30 [Epoch 1 Batch 680/4610] loss=1.0656, lr=0.0000059, metrics:accuracy:0.4372
INFO:root:22:01:33 [Epoch 1 Batch 720/4610] loss=1.1092, lr=0.0000062, metrics:accuracy:0.4416
INFO:root:22:01:36 [Epoch 1 Batch 760/4610] loss=1.0525, lr=0.0000066, metrics:accuracy:0.4455
INFO:root:22:01:39 [Epoch 1 Batch 800/4610] loss=1.0217, lr=0.0000069, metrics:accuracy:0.4501
INFO:root:22:01:42 [Epoch 1 Batch 840/4610] loss=1.0602, lr=0.0000073, metrics:accuracy:0.4550
INFO:root:22:01:45 [Epoch 1 Batch 880/4610] loss=1.1332, lr=0.0000076, metrics:accuracy:0.4561
INFO:root:22:01:48 [Epoch 1 Batch 920/4610] loss=1.1406, lr=0.0000080, metrics:accuracy:0.4587
INFO:root:22:01:51 [Epoch 1 Batch 960/4610] loss=1.0521, lr=0.0000083, metrics:accuracy:0.4609
INFO:root:22:01:53 [Epoch 1 Batch 1000/4610] loss=1.0982, lr=0.0000087, metrics:accuracy:0.4630
INFO:root:22:01:57 [Epoch 1 Batch 1040/4610] loss=1.0376, lr=0.0000090, metrics:accuracy:0.4640
INFO:root:22:01:59 [Epoch 1 Batch 1080/4610] loss=1.1637, lr=0.0000094, metrics:accuracy:0.4635
INFO:root:22:02:02 [Epoch 1 Batch 1120/4610] loss=1.1187, lr=0.0000097, metrics:accuracy:0.4637
INFO:root:22:02:05 [Epoch 1 Batch 1160/4610] loss=1.0174, lr=0.0000101, metrics:accuracy:0.4658
INFO:root:22:02:08 [Epoch 1 Batch 1200/4610] loss=1.0818, lr=0.0000104, metrics:accuracy:0.4677
INFO:root:22:02:11 [Epoch 1 Batch 1240/4610] loss=1.0459, lr=0.0000107, metrics:accuracy:0.4689
INFO:root:22:02:14 [Epoch 1 Batch 1280/4610] loss=1.0319, lr=0.0000111, metrics:accuracy:0.4708
INFO:root:22:02:17 [Epoch 1 Batch 1320/4610] loss=1.0983, lr=0.0000114, metrics:accuracy:0.4714
INFO:root:22:02:20 [Epoch 1 Batch 1360/4610] loss=1.0687, lr=0.0000118, metrics:accuracy:0.4723
INFO:root:22:02:23 [Epoch 1 Batch 1400/4610] loss=1.0925, lr=0.0000121, metrics:accuracy:0.4736
INFO:root:22:02:26 [Epoch 1 Batch 1440/4610] loss=1.0643, lr=0.0000125, metrics:accuracy:0.4741
INFO:root:22:02:29 [Epoch 1 Batch 1480/4610] loss=1.0676, lr=0.0000128, metrics:accuracy:0.4746
INFO:root:22:02:31 [Epoch 1 Batch 1520/4610] loss=1.0238, lr=0.0000132, metrics:accuracy:0.4755
INFO:root:22:02:35 [Epoch 1 Batch 1560/4610] loss=1.0536, lr=0.0000135, metrics:accuracy:0.4763
INFO:root:22:02:37 [Epoch 1 Batch 1600/4610] loss=1.0100, lr=0.0000139, metrics:accuracy:0.4773
INFO:root:22:02:40 [Epoch 1 Batch 1640/4610] loss=1.1172, lr=0.0000142, metrics:accuracy:0.4776
INFO:root:22:02:43 [Epoch 1 Batch 1680/4610] loss=1.0546, lr=0.0000146, metrics:accuracy:0.4783
INFO:root:22:02:46 [Epoch 1 Batch 1720/4610] loss=1.1106, lr=0.0000149, metrics:accuracy:0.4787
INFO:root:22:02:49 [Epoch 1 Batch 1760/4610] loss=1.0141, lr=0.0000153, metrics:accuracy:0.4790
INFO:root:22:02:52 [Epoch 1 Batch 1800/4610] loss=1.0085, lr=0.0000156, metrics:accuracy:0.4804
INFO:root:22:02:55 [Epoch 1 Batch 1840/4610] loss=1.0626, lr=0.0000160, metrics:accuracy:0.4806
INFO:root:22:02:58 [Epoch 1 Batch 1880/4610] loss=1.0668, lr=0.0000163, metrics:accuracy:0.4805
INFO:root:22:03:01 [Epoch 1 Batch 1920/4610] loss=1.0729, lr=0.0000167, metrics:accuracy:0.4808
INFO:root:22:03:04 [Epoch 1 Batch 1960/4610] loss=1.1113, lr=0.0000170, metrics:accuracy:0.4811
INFO:root:22:03:07 [Epoch 1 Batch 2000/4610] loss=1.0462, lr=0.0000174, metrics:accuracy:0.4812
INFO:root:22:03:09 [Epoch 1 Batch 2040/4610] loss=0.9721, lr=0.0000177, metrics:accuracy:0.4829
INFO:root:22:03:13 [Epoch 1 Batch 2080/4610] loss=1.0426, lr=0.0000181, metrics:accuracy:0.4833
INFO:root:22:03:15 [Epoch 1 Batch 2120/4610] loss=1.0372, lr=0.0000184, metrics:accuracy:0.4842
INFO:root:22:03:18 [Epoch 1 Batch 2160/4610] loss=1.0367, lr=0.0000187, metrics:accuracy:0.4846
INFO:root:22:03:21 [Epoch 1 Batch 2200/4610] loss=0.9985, lr=0.0000191, metrics:accuracy:0.4854
INFO:root:22:03:24 [Epoch 1 Batch 2240/4610] loss=0.9801, lr=0.0000194, metrics:accuracy:0.4864
INFO:root:22:03:27 [Epoch 1 Batch 2280/4610] loss=0.9339, lr=0.0000198, metrics:accuracy:0.4877
INFO:root:22:03:30 [Epoch 1 Batch 2320/4610] loss=1.0172, lr=0.0000200, metrics:accuracy:0.4883
INFO:root:22:03:33 [Epoch 1 Batch 2360/4610] loss=0.9901, lr=0.0000199, metrics:accuracy:0.4895
INFO:root:22:03:36 [Epoch 1 Batch 2400/4610] loss=1.0737, lr=0.0000199, metrics:accuracy:0.4899
INFO:root:22:03:39 [Epoch 1 Batch 2440/4610] loss=1.0069, lr=0.0000199, metrics:accuracy:0.4902
INFO:root:22:03:42 [Epoch 1 Batch 2480/4610] loss=1.0358, lr=0.0000198, metrics:accuracy:0.4902
INFO:root:22:03:45 [Epoch 1 Batch 2520/4610] loss=0.9753, lr=0.0000198, metrics:accuracy:0.4913
INFO:root:22:03:48 [Epoch 1 Batch 2560/4610] loss=1.0315, lr=0.0000198, metrics:accuracy:0.4915
INFO:root:22:03:50 [Epoch 1 Batch 2600/4610] loss=1.1409, lr=0.0000197, metrics:accuracy:0.4911
INFO:root:22:03:54 [Epoch 1 Batch 2640/4610] loss=1.0703, lr=0.0000197, metrics:accuracy:0.4913
INFO:root:22:03:56 [Epoch 1 Batch 2680/4610] loss=1.0533, lr=0.0000196, metrics:accuracy:0.4915
INFO:root:22:03:59 [Epoch 1 Batch 2720/4610] loss=1.0105, lr=0.0000196, metrics:accuracy:0.4924
INFO:root:22:04:02 [Epoch 1 Batch 2760/4610] loss=1.0426, lr=0.0000196, metrics:accuracy:0.4926
INFO:root:22:04:05 [Epoch 1 Batch 2800/4610] loss=1.0958, lr=0.0000195, metrics:accuracy:0.4926
INFO:root:22:04:08 [Epoch 1 Batch 2840/4610] loss=1.0847, lr=0.0000195, metrics:accuracy:0.4928
INFO:root:22:04:11 [Epoch 1 Batch 2880/4610] loss=1.0581, lr=0.0000194, metrics:accuracy:0.4927
INFO:root:22:04:14 [Epoch 1 Batch 2920/4610] loss=1.0090, lr=0.0000194, metrics:accuracy:0.4936
INFO:root:22:04:17 [Epoch 1 Batch 2960/4610] loss=1.0155, lr=0.0000194, metrics:accuracy:0.4944
INFO:root:22:04:20 [Epoch 1 Batch 3000/4610] loss=1.0233, lr=0.0000193, metrics:accuracy:0.4946
INFO:root:22:04:23 [Epoch 1 Batch 3040/4610] loss=0.9688, lr=0.0000193, metrics:accuracy:0.4954
INFO:root:22:04:26 [Epoch 1 Batch 3080/4610] loss=1.0316, lr=0.0000193, metrics:accuracy:0.4953
INFO:root:22:04:28 [Epoch 1 Batch 3120/4610] loss=1.0292, lr=0.0000192, metrics:accuracy:0.4958
INFO:root:22:04:31 [Epoch 1 Batch 3160/4610] loss=1.0703, lr=0.0000192, metrics:accuracy:0.4958
INFO:root:22:04:35 [Epoch 1 Batch 3200/4610] loss=1.0051, lr=0.0000191, metrics:accuracy:0.4959
INFO:root:22:04:37 [Epoch 1 Batch 3240/4610] loss=1.0258, lr=0.0000191, metrics:accuracy:0.4961
INFO:root:22:04:40 [Epoch 1 Batch 3280/4610] loss=1.0292, lr=0.0000191, metrics:accuracy:0.4967
INFO:root:22:04:43 [Epoch 1 Batch 3320/4610] loss=1.0440, lr=0.0000190, metrics:accuracy:0.4970
INFO:root:22:04:46 [Epoch 1 Batch 3360/4610] loss=0.9803, lr=0.0000190, metrics:accuracy:0.4973
INFO:root:22:04:49 [Epoch 1 Batch 3400/4610] loss=1.0677, lr=0.0000189, metrics:accuracy:0.4978
INFO:root:22:04:52 [Epoch 1 Batch 3440/4610] loss=0.9953, lr=0.0000189, metrics:accuracy:0.4984
INFO:root:22:04:54 [Epoch 1 Batch 3480/4610] loss=1.0261, lr=0.0000189, metrics:accuracy:0.4987
INFO:root:22:04:57 [Epoch 1 Batch 3520/4610] loss=1.0480, lr=0.0000188, metrics:accuracy:0.4990
INFO:root:22:05:00 [Epoch 1 Batch 3560/4610] loss=1.0697, lr=0.0000188, metrics:accuracy:0.4991
INFO:root:22:05:03 [Epoch 1 Batch 3600/4610] loss=1.0428, lr=0.0000187, metrics:accuracy:0.4988
INFO:root:22:05:06 [Epoch 1 Batch 3640/4610] loss=1.0105, lr=0.0000187, metrics:accuracy:0.4989
INFO:root:22:05:08 [Epoch 1 Batch 3680/4610] loss=1.0261, lr=0.0000187, metrics:accuracy:0.4991
INFO:root:22:05:11 [Epoch 1 Batch 3720/4610] loss=1.0181, lr=0.0000186, metrics:accuracy:0.4993
INFO:root:22:05:14 [Epoch 1 Batch 3760/4610] loss=0.9362, lr=0.0000186, metrics:accuracy:0.4999
INFO:root:22:05:17 [Epoch 1 Batch 3800/4610] loss=1.0345, lr=0.0000186, metrics:accuracy:0.5004
INFO:root:22:05:20 [Epoch 1 Batch 3840/4610] loss=1.0602, lr=0.0000185, metrics:accuracy:0.5005
INFO:root:22:05:23 [Epoch 1 Batch 3880/4610] loss=1.0904, lr=0.0000185, metrics:accuracy:0.5009
INFO:root:22:05:26 [Epoch 1 Batch 3920/4610] loss=1.0250, lr=0.0000184, metrics:accuracy:0.5011
INFO:root:22:05:28 [Epoch 1 Batch 3960/4610] loss=1.0107, lr=0.0000184, metrics:accuracy:0.5016
INFO:root:22:05:31 [Epoch 1 Batch 4000/4610] loss=1.0563, lr=0.0000184, metrics:accuracy:0.5020
INFO:root:22:05:34 [Epoch 1 Batch 4040/4610] loss=1.0042, lr=0.0000183, metrics:accuracy:0.5022
INFO:root:22:05:37 [Epoch 1 Batch 4080/4610] loss=1.0103, lr=0.0000183, metrics:accuracy:0.5024
INFO:root:22:05:40 [Epoch 1 Batch 4120/4610] loss=0.9902, lr=0.0000182, metrics:accuracy:0.5025
INFO:root:22:05:43 [Epoch 1 Batch 4160/4610] loss=0.9937, lr=0.0000182, metrics:accuracy:0.5028
INFO:root:22:05:46 [Epoch 1 Batch 4200/4610] loss=1.0588, lr=0.0000182, metrics:accuracy:0.5026
INFO:root:22:05:48 [Epoch 1 Batch 4240/4610] loss=0.9654, lr=0.0000181, metrics:accuracy:0.5031
INFO:root:22:05:52 [Epoch 1 Batch 4280/4610] loss=0.9928, lr=0.0000181, metrics:accuracy:0.5034
INFO:root:22:05:54 [Epoch 1 Batch 4320/4610] loss=1.0149, lr=0.0000181, metrics:accuracy:0.5038
INFO:root:22:05:57 [Epoch 1 Batch 4360/4610] loss=0.9612, lr=0.0000180, metrics:accuracy:0.5042
INFO:root:22:06:01 [Epoch 1 Batch 4400/4610] loss=1.0174, lr=0.0000180, metrics:accuracy:0.5041
INFO:root:22:06:03 [Epoch 1 Batch 4440/4610] loss=1.0498, lr=0.0000179, metrics:accuracy:0.5041
INFO:root:22:06:06 [Epoch 1 Batch 4480/4610] loss=0.9999, lr=0.0000179, metrics:accuracy:0.5045
INFO:root:22:06:09 [Epoch 1 Batch 4520/4610] loss=0.9905, lr=0.0000179, metrics:accuracy:0.5047
INFO:root:22:06:12 [Epoch 1 Batch 4560/4610] loss=1.0492, lr=0.0000178, metrics:accuracy:0.5048
INFO:root:22:06:15 [Epoch 1 Batch 4600/4610] loss=1.0883, lr=0.0000178, metrics:accuracy:0.5047
INFO:root:22:06:16 Now we are doing evaluation on dev with gpu(0).
INFO:root:22:06:17 [Batch 40/618] loss=0.9224, metrics:accuracy:0.5750
INFO:root:22:06:18 [Batch 80/618] loss=1.0558, metrics:accuracy:0.5375
INFO:root:22:06:19 [Batch 120/618] loss=1.0152, metrics:accuracy:0.5167
INFO:root:22:06:20 [Batch 160/618] loss=1.0281, metrics:accuracy:0.5219
INFO:root:22:06:22 [Batch 200/618] loss=0.9748, metrics:accuracy:0.5294
INFO:root:22:06:23 [Batch 240/618] loss=1.0298, metrics:accuracy:0.5266
INFO:root:22:06:24 [Batch 280/618] loss=1.0278, metrics:accuracy:0.5246
INFO:root:22:06:25 [Batch 320/618] loss=1.0327, metrics:accuracy:0.5238
INFO:root:22:06:26 [Batch 360/618] loss=0.9782, metrics:accuracy:0.5288
INFO:root:22:06:27 [Batch 400/618] loss=0.9845, metrics:accuracy:0.5312
INFO:root:22:06:28 [Batch 440/618] loss=0.9348, metrics:accuracy:0.5344
INFO:root:22:06:30 [Batch 480/618] loss=0.9817, metrics:accuracy:0.5354
INFO:root:22:06:31 [Batch 520/618] loss=0.9697, metrics:accuracy:0.5368
INFO:root:22:06:32 [Batch 560/618] loss=0.9401, metrics:accuracy:0.5395
INFO:root:22:06:33 [Batch 600/618] loss=0.9850, metrics:accuracy:0.5381
INFO:root:22:06:33 validation metrics:accuracy:0.5374
INFO:root:22:06:33 Time cost=17.88s, throughput=276.55 samples/s
INFO:root:22:06:35 params saved in: ./output_dir/model_bert_meituan_0.params
INFO:root:22:06:35 Time cost=352.92s
INFO:root:22:06:38 [Epoch 2 Batch 40/4610] loss=0.9239, lr=0.0000177, metrics:accuracy:0.5656
INFO:root:22:06:41 [Epoch 2 Batch 80/4610] loss=0.9915, lr=0.0000177, metrics:accuracy:0.5453
INFO:root:22:06:44 [Epoch 2 Batch 120/4610] loss=0.9852, lr=0.0000177, metrics:accuracy:0.5563
INFO:root:22:06:46 [Epoch 2 Batch 160/4610] loss=1.0000, lr=0.0000176, metrics:accuracy:0.5477
INFO:root:22:06:50 [Epoch 2 Batch 200/4610] loss=0.9410, lr=0.0000176, metrics:accuracy:0.5475
INFO:root:22:06:52 [Epoch 2 Batch 240/4610] loss=0.9595, lr=0.0000175, metrics:accuracy:0.5516
INFO:root:22:06:55 [Epoch 2 Batch 280/4610] loss=0.9781, lr=0.0000175, metrics:accuracy:0.5509
INFO:root:22:06:58 [Epoch 2 Batch 320/4610] loss=0.9515, lr=0.0000175, metrics:accuracy:0.5527
INFO:root:22:07:01 [Epoch 2 Batch 360/4610] loss=0.8843, lr=0.0000174, metrics:accuracy:0.5576
INFO:root:22:07:04 [Epoch 2 Batch 400/4610] loss=0.9524, lr=0.0000174, metrics:accuracy:0.5578
INFO:root:22:07:07 [Epoch 2 Batch 440/4610] loss=0.9252, lr=0.0000174, metrics:accuracy:0.5605
INFO:root:22:07:10 [Epoch 2 Batch 480/4610] loss=0.9099, lr=0.0000173, metrics:accuracy:0.5628
INFO:root:22:07:13 [Epoch 2 Batch 520/4610] loss=0.9496, lr=0.0000173, metrics:accuracy:0.5620
INFO:root:22:07:16 [Epoch 2 Batch 560/4610] loss=1.0634, lr=0.0000172, metrics:accuracy:0.5556
INFO:root:22:07:19 [Epoch 2 Batch 600/4610] loss=0.9885, lr=0.0000172, metrics:accuracy:0.5540
INFO:root:22:07:22 [Epoch 2 Batch 640/4610] loss=0.9745, lr=0.0000172, metrics:accuracy:0.5530
INFO:root:22:07:24 [Epoch 2 Batch 680/4610] loss=0.9851, lr=0.0000171, metrics:accuracy:0.5517
INFO:root:22:07:28 [Epoch 2 Batch 720/4610] loss=0.9388, lr=0.0000171, metrics:accuracy:0.5525
INFO:root:22:07:30 [Epoch 2 Batch 760/4610] loss=0.9558, lr=0.0000170, metrics:accuracy:0.5533
INFO:root:22:07:33 [Epoch 2 Batch 800/4610] loss=0.9171, lr=0.0000170, metrics:accuracy:0.5532
INFO:root:22:07:36 [Epoch 2 Batch 840/4610] loss=1.0594, lr=0.0000170, metrics:accuracy:0.5524
INFO:root:22:07:39 [Epoch 2 Batch 880/4610] loss=1.0314, lr=0.0000169, metrics:accuracy:0.5514
INFO:root:22:07:42 [Epoch 2 Batch 920/4610] loss=0.9610, lr=0.0000169, metrics:accuracy:0.5533
INFO:root:22:07:45 [Epoch 2 Batch 960/4610] loss=0.9482, lr=0.0000169, metrics:accuracy:0.5542
INFO:root:22:07:48 [Epoch 2 Batch 1000/4610] loss=0.9090, lr=0.0000168, metrics:accuracy:0.5545
INFO:root:22:07:51 [Epoch 2 Batch 1040/4610] loss=0.9403, lr=0.0000168, metrics:accuracy:0.5553
INFO:root:22:07:54 [Epoch 2 Batch 1080/4610] loss=0.9435, lr=0.0000167, metrics:accuracy:0.5562
INFO:root:22:07:57 [Epoch 2 Batch 1120/4610] loss=0.9917, lr=0.0000167, metrics:accuracy:0.5556
INFO:root:22:08:00 [Epoch 2 Batch 1160/4610] loss=0.9823, lr=0.0000167, metrics:accuracy:0.5551
INFO:root:22:08:02 [Epoch 2 Batch 1200/4610] loss=0.9375, lr=0.0000166, metrics:accuracy:0.5558
INFO:root:22:08:06 [Epoch 2 Batch 1240/4610] loss=1.0132, lr=0.0000166, metrics:accuracy:0.5547
INFO:root:22:08:08 [Epoch 2 Batch 1280/4610] loss=0.9649, lr=0.0000165, metrics:accuracy:0.5552
INFO:root:22:08:11 [Epoch 2 Batch 1320/4610] loss=0.9542, lr=0.0000165, metrics:accuracy:0.5558
INFO:root:22:08:14 [Epoch 2 Batch 1360/4610] loss=0.8975, lr=0.0000165, metrics:accuracy:0.5568
INFO:root:22:08:17 [Epoch 2 Batch 1400/4610] loss=0.9736, lr=0.0000164, metrics:accuracy:0.5568
INFO:root:22:08:20 [Epoch 2 Batch 1440/4610] loss=1.0408, lr=0.0000164, metrics:accuracy:0.5562
INFO:root:22:08:23 [Epoch 2 Batch 1480/4610] loss=0.9482, lr=0.0000163, metrics:accuracy:0.5574
INFO:root:22:08:26 [Epoch 2 Batch 1520/4610] loss=0.9772, lr=0.0000163, metrics:accuracy:0.5569
INFO:root:22:08:29 [Epoch 2 Batch 1560/4610] loss=0.9500, lr=0.0000163, metrics:accuracy:0.5560
INFO:root:22:08:32 [Epoch 2 Batch 1600/4610] loss=0.8821, lr=0.0000162, metrics:accuracy:0.5564
INFO:root:22:08:35 [Epoch 2 Batch 1640/4610] loss=0.8985, lr=0.0000162, metrics:accuracy:0.5572
INFO:root:22:08:38 [Epoch 2 Batch 1680/4610] loss=0.9642, lr=0.0000162, metrics:accuracy:0.5574
INFO:root:22:08:40 [Epoch 2 Batch 1720/4610] loss=0.9490, lr=0.0000161, metrics:accuracy:0.5576
INFO:root:22:08:43 [Epoch 2 Batch 1760/4610] loss=0.8451, lr=0.0000161, metrics:accuracy:0.5587
INFO:root:22:08:46 [Epoch 2 Batch 1800/4610] loss=0.9372, lr=0.0000160, metrics:accuracy:0.5589
INFO:root:22:08:49 [Epoch 2 Batch 1840/4610] loss=0.9527, lr=0.0000160, metrics:accuracy:0.5591
INFO:root:22:08:52 [Epoch 2 Batch 1880/4610] loss=0.8861, lr=0.0000160, metrics:accuracy:0.5605
INFO:root:22:08:55 [Epoch 2 Batch 1920/4610] loss=0.9671, lr=0.0000159, metrics:accuracy:0.5605
INFO:root:22:08:57 [Epoch 2 Batch 1960/4610] loss=0.9820, lr=0.0000159, metrics:accuracy:0.5597
INFO:root:22:09:00 [Epoch 2 Batch 2000/4610] loss=0.8997, lr=0.0000158, metrics:accuracy:0.5602
INFO:root:22:09:03 [Epoch 2 Batch 2040/4610] loss=0.9402, lr=0.0000158, metrics:accuracy:0.5597
INFO:root:22:09:06 [Epoch 2 Batch 2080/4610] loss=0.9098, lr=0.0000158, metrics:accuracy:0.5603
INFO:root:22:09:09 [Epoch 2 Batch 2120/4610] loss=0.9273, lr=0.0000157, metrics:accuracy:0.5606
INFO:root:22:09:11 [Epoch 2 Batch 2160/4610] loss=0.9732, lr=0.0000157, metrics:accuracy:0.5605
INFO:root:22:09:14 [Epoch 2 Batch 2200/4610] loss=0.9166, lr=0.0000157, metrics:accuracy:0.5606
INFO:root:22:09:17 [Epoch 2 Batch 2240/4610] loss=0.9222, lr=0.0000156, metrics:accuracy:0.5610
INFO:root:22:09:20 [Epoch 2 Batch 2280/4610] loss=0.9180, lr=0.0000156, metrics:accuracy:0.5610
INFO:root:22:09:23 [Epoch 2 Batch 2320/4610] loss=0.9686, lr=0.0000155, metrics:accuracy:0.5618
INFO:root:22:09:26 [Epoch 2 Batch 2360/4610] loss=0.9458, lr=0.0000155, metrics:accuracy:0.5625
INFO:root:22:09:29 [Epoch 2 Batch 2400/4610] loss=1.0039, lr=0.0000155, metrics:accuracy:0.5620
INFO:root:22:09:31 [Epoch 2 Batch 2440/4610] loss=0.9506, lr=0.0000154, metrics:accuracy:0.5625
INFO:root:22:09:34 [Epoch 2 Batch 2480/4610] loss=0.8946, lr=0.0000154, metrics:accuracy:0.5629
INFO:root:22:09:37 [Epoch 2 Batch 2520/4610] loss=0.9544, lr=0.0000153, metrics:accuracy:0.5628
INFO:root:22:09:40 [Epoch 2 Batch 2560/4610] loss=0.9213, lr=0.0000153, metrics:accuracy:0.5629
INFO:root:22:09:43 [Epoch 2 Batch 2600/4610] loss=0.9349, lr=0.0000153, metrics:accuracy:0.5626
INFO:root:22:09:46 [Epoch 2 Batch 2640/4610] loss=0.9167, lr=0.0000152, metrics:accuracy:0.5624
INFO:root:22:09:49 [Epoch 2 Batch 2680/4610] loss=0.8432, lr=0.0000152, metrics:accuracy:0.5635
INFO:root:22:09:52 [Epoch 2 Batch 2720/4610] loss=0.9930, lr=0.0000152, metrics:accuracy:0.5634
INFO:root:22:09:55 [Epoch 2 Batch 2760/4610] loss=1.0031, lr=0.0000151, metrics:accuracy:0.5632
INFO:root:22:09:58 [Epoch 2 Batch 2800/4610] loss=1.0079, lr=0.0000151, metrics:accuracy:0.5625
INFO:root:22:10:00 [Epoch 2 Batch 2840/4610] loss=0.9072, lr=0.0000150, metrics:accuracy:0.5630
INFO:root:22:10:03 [Epoch 2 Batch 2880/4610] loss=0.9391, lr=0.0000150, metrics:accuracy:0.5629
INFO:root:22:10:06 [Epoch 2 Batch 2920/4610] loss=0.8874, lr=0.0000150, metrics:accuracy:0.5630
INFO:root:22:10:09 [Epoch 2 Batch 2960/4610] loss=0.9498, lr=0.0000149, metrics:accuracy:0.5629
INFO:root:22:10:12 [Epoch 2 Batch 3000/4610] loss=0.9733, lr=0.0000149, metrics:accuracy:0.5623
INFO:root:22:10:15 [Epoch 2 Batch 3040/4610] loss=0.9449, lr=0.0000148, metrics:accuracy:0.5618
INFO:root:22:10:18 [Epoch 2 Batch 3080/4610] loss=0.9353, lr=0.0000148, metrics:accuracy:0.5620
INFO:root:22:10:21 [Epoch 2 Batch 3120/4610] loss=0.9210, lr=0.0000148, metrics:accuracy:0.5623
INFO:root:22:10:24 [Epoch 2 Batch 3160/4610] loss=0.8875, lr=0.0000147, metrics:accuracy:0.5628
INFO:root:22:10:27 [Epoch 2 Batch 3200/4610] loss=0.9891, lr=0.0000147, metrics:accuracy:0.5625
INFO:root:22:10:30 [Epoch 2 Batch 3240/4610] loss=0.9676, lr=0.0000147, metrics:accuracy:0.5623
INFO:root:22:10:32 [Epoch 2 Batch 3280/4610] loss=0.8716, lr=0.0000146, metrics:accuracy:0.5632
INFO:root:22:10:36 [Epoch 2 Batch 3320/4610] loss=0.9848, lr=0.0000146, metrics:accuracy:0.5632
INFO:root:22:10:38 [Epoch 2 Batch 3360/4610] loss=0.8608, lr=0.0000145, metrics:accuracy:0.5640
INFO:root:22:10:41 [Epoch 2 Batch 3400/4610] loss=0.9031, lr=0.0000145, metrics:accuracy:0.5641
INFO:root:22:10:45 [Epoch 2 Batch 3440/4610] loss=0.9639, lr=0.0000145, metrics:accuracy:0.5641
INFO:root:22:10:47 [Epoch 2 Batch 3480/4610] loss=0.9254, lr=0.0000144, metrics:accuracy:0.5638
INFO:root:22:10:50 [Epoch 2 Batch 3520/4610] loss=0.9202, lr=0.0000144, metrics:accuracy:0.5638
INFO:root:22:10:53 [Epoch 2 Batch 3560/4610] loss=0.8919, lr=0.0000143, metrics:accuracy:0.5641
INFO:root:22:10:56 [Epoch 2 Batch 3600/4610] loss=0.9554, lr=0.0000143, metrics:accuracy:0.5640
INFO:root:22:10:59 [Epoch 2 Batch 3640/4610] loss=0.9594, lr=0.0000143, metrics:accuracy:0.5643
INFO:root:22:11:02 [Epoch 2 Batch 3680/4610] loss=0.9592, lr=0.0000142, metrics:accuracy:0.5644
INFO:root:22:11:05 [Epoch 2 Batch 3720/4610] loss=0.8795, lr=0.0000142, metrics:accuracy:0.5647
INFO:root:22:11:08 [Epoch 2 Batch 3760/4610] loss=1.0238, lr=0.0000141, metrics:accuracy:0.5642
INFO:root:22:11:11 [Epoch 2 Batch 3800/4610] loss=0.9245, lr=0.0000141, metrics:accuracy:0.5647
INFO:root:22:11:14 [Epoch 2 Batch 3840/4610] loss=0.9588, lr=0.0000141, metrics:accuracy:0.5647
INFO:root:22:11:16 [Epoch 2 Batch 3880/4610] loss=0.9456, lr=0.0000140, metrics:accuracy:0.5647
INFO:root:22:11:19 [Epoch 2 Batch 3920/4610] loss=0.9517, lr=0.0000140, metrics:accuracy:0.5646
INFO:root:22:11:22 [Epoch 2 Batch 3960/4610] loss=0.9476, lr=0.0000140, metrics:accuracy:0.5646
INFO:root:22:11:25 [Epoch 2 Batch 4000/4610] loss=0.9326, lr=0.0000139, metrics:accuracy:0.5646
INFO:root:22:11:28 [Epoch 2 Batch 4040/4610] loss=0.9370, lr=0.0000139, metrics:accuracy:0.5643
INFO:root:22:11:31 [Epoch 2 Batch 4080/4610] loss=0.9237, lr=0.0000138, metrics:accuracy:0.5642
INFO:root:22:11:34 [Epoch 2 Batch 4120/4610] loss=0.8922, lr=0.0000138, metrics:accuracy:0.5646
INFO:root:22:11:37 [Epoch 2 Batch 4160/4610] loss=0.9467, lr=0.0000138, metrics:accuracy:0.5648
INFO:root:22:11:40 [Epoch 2 Batch 4200/4610] loss=0.9500, lr=0.0000137, metrics:accuracy:0.5647
INFO:root:22:11:43 [Epoch 2 Batch 4240/4610] loss=0.9114, lr=0.0000137, metrics:accuracy:0.5647
INFO:root:22:11:46 [Epoch 2 Batch 4280/4610] loss=0.8332, lr=0.0000136, metrics:accuracy:0.5651
INFO:root:22:11:48 [Epoch 2 Batch 4320/4610] loss=0.8970, lr=0.0000136, metrics:accuracy:0.5654
INFO:root:22:11:52 [Epoch 2 Batch 4360/4610] loss=0.9440, lr=0.0000136, metrics:accuracy:0.5657
INFO:root:22:11:54 [Epoch 2 Batch 4400/4610] loss=0.9401, lr=0.0000135, metrics:accuracy:0.5657
INFO:root:22:11:57 [Epoch 2 Batch 4440/4610] loss=0.9436, lr=0.0000135, metrics:accuracy:0.5658
INFO:root:22:12:00 [Epoch 2 Batch 4480/4610] loss=0.8832, lr=0.0000135, metrics:accuracy:0.5663
INFO:root:22:12:03 [Epoch 2 Batch 4520/4610] loss=0.9811, lr=0.0000134, metrics:accuracy:0.5659
INFO:root:22:12:06 [Epoch 2 Batch 4560/4610] loss=0.9619, lr=0.0000134, metrics:accuracy:0.5658
INFO:root:22:12:09 [Epoch 2 Batch 4600/4610] loss=0.9199, lr=0.0000133, metrics:accuracy:0.5659
INFO:root:22:12:10 Now we are doing evaluation on dev with gpu(0).
INFO:root:22:12:11 [Batch 40/618] loss=0.8953, metrics:accuracy:0.6000
INFO:root:22:12:12 [Batch 80/618] loss=1.0425, metrics:accuracy:0.5656
INFO:root:22:12:13 [Batch 120/618] loss=1.0046, metrics:accuracy:0.5573
INFO:root:22:12:14 [Batch 160/618] loss=1.0377, metrics:accuracy:0.5508
INFO:root:22:12:16 [Batch 200/618] loss=0.9384, metrics:accuracy:0.5550
INFO:root:22:12:17 [Batch 240/618] loss=1.0185, metrics:accuracy:0.5448
INFO:root:22:12:18 [Batch 280/618] loss=0.9985, metrics:accuracy:0.5455
INFO:root:22:12:19 [Batch 320/618] loss=1.0493, metrics:accuracy:0.5434
INFO:root:22:12:20 [Batch 360/618] loss=0.9780, metrics:accuracy:0.5458
INFO:root:22:12:22 [Batch 400/618] loss=0.9901, metrics:accuracy:0.5509
INFO:root:22:12:23 [Batch 440/618] loss=0.9263, metrics:accuracy:0.5551
INFO:root:22:12:24 [Batch 480/618] loss=0.9728, metrics:accuracy:0.5534
INFO:root:22:12:25 [Batch 520/618] loss=0.8932, metrics:accuracy:0.5553
INFO:root:22:12:26 [Batch 560/618] loss=0.9446, metrics:accuracy:0.5583
INFO:root:22:12:27 [Batch 600/618] loss=0.9630, metrics:accuracy:0.5592
INFO:root:22:12:28 validation metrics:accuracy:0.5587
INFO:root:22:12:28 Time cost=18.02s, throughput=274.36 samples/s
INFO:root:22:12:29 params saved in: ./output_dir/model_bert_meituan_1.params
INFO:root:22:12:29 Time cost=354.13s
INFO:root:22:12:32 [Epoch 3 Batch 40/4610] loss=0.9330, lr=0.0000133, metrics:accuracy:0.5594
INFO:root:22:12:35 [Epoch 3 Batch 80/4610] loss=0.8196, lr=0.0000133, metrics:accuracy:0.6156
INFO:root:22:12:38 [Epoch 3 Batch 120/4610] loss=0.8084, lr=0.0000132, metrics:accuracy:0.6156
INFO:root:22:12:41 [Epoch 3 Batch 160/4610] loss=0.7972, lr=0.0000132, metrics:accuracy:0.6172
INFO:root:22:12:44 [Epoch 3 Batch 200/4610] loss=0.8064, lr=0.0000131, metrics:accuracy:0.6219
INFO:root:22:12:46 [Epoch 3 Batch 240/4610] loss=0.8414, lr=0.0000131, metrics:accuracy:0.6224
INFO:root:22:12:49 [Epoch 3 Batch 280/4610] loss=0.8297, lr=0.0000131, metrics:accuracy:0.6254
INFO:root:22:12:52 [Epoch 3 Batch 320/4610] loss=0.8749, lr=0.0000130, metrics:accuracy:0.6234
INFO:root:22:12:55 [Epoch 3 Batch 360/4610] loss=0.8454, lr=0.0000130, metrics:accuracy:0.6201
INFO:root:22:12:58 [Epoch 3 Batch 400/4610] loss=0.8459, lr=0.0000129, metrics:accuracy:0.6262
INFO:root:22:13:01 [Epoch 3 Batch 440/4610] loss=0.8906, lr=0.0000129, metrics:accuracy:0.6284
INFO:root:22:13:03 [Epoch 3 Batch 480/4610] loss=0.9147, lr=0.0000129, metrics:accuracy:0.6271
INFO:root:22:13:06 [Epoch 3 Batch 520/4610] loss=0.8677, lr=0.0000128, metrics:accuracy:0.6286
INFO:root:22:13:09 [Epoch 3 Batch 560/4610] loss=0.7962, lr=0.0000128, metrics:accuracy:0.6288
INFO:root:22:13:12 [Epoch 3 Batch 600/4610] loss=0.7991, lr=0.0000128, metrics:accuracy:0.6287
INFO:root:22:13:15 [Epoch 3 Batch 640/4610] loss=0.8725, lr=0.0000127, metrics:accuracy:0.6260
INFO:root:22:13:18 [Epoch 3 Batch 680/4610] loss=0.8841, lr=0.0000127, metrics:accuracy:0.6242
INFO:root:22:13:20 [Epoch 3 Batch 720/4610] loss=0.8055, lr=0.0000126, metrics:accuracy:0.6253
INFO:root:22:13:23 [Epoch 3 Batch 760/4610] loss=0.8462, lr=0.0000126, metrics:accuracy:0.6238
INFO:root:22:13:26 [Epoch 3 Batch 800/4610] loss=0.8143, lr=0.0000126, metrics:accuracy:0.6237
INFO:root:22:13:29 [Epoch 3 Batch 840/4610] loss=0.8546, lr=0.0000125, metrics:accuracy:0.6226
INFO:root:22:13:32 [Epoch 3 Batch 880/4610] loss=0.9038, lr=0.0000125, metrics:accuracy:0.6214
INFO:root:22:13:35 [Epoch 3 Batch 920/4610] loss=0.7640, lr=0.0000124, metrics:accuracy:0.6228
INFO:root:22:13:37 [Epoch 3 Batch 960/4610] loss=0.8679, lr=0.0000124, metrics:accuracy:0.6245
INFO:root:22:13:41 [Epoch 3 Batch 1000/4610] loss=0.7909, lr=0.0000124, metrics:accuracy:0.6261
INFO:root:22:13:44 [Epoch 3 Batch 1040/4610] loss=0.8097, lr=0.0000123, metrics:accuracy:0.6262
INFO:root:22:13:46 [Epoch 3 Batch 1080/4610] loss=0.7994, lr=0.0000123, metrics:accuracy:0.6261
INFO:root:22:13:50 [Epoch 3 Batch 1120/4610] loss=0.8723, lr=0.0000123, metrics:accuracy:0.6257
INFO:root:22:13:52 [Epoch 3 Batch 1160/4610] loss=0.8302, lr=0.0000122, metrics:accuracy:0.6248
INFO:root:22:13:55 [Epoch 3 Batch 1200/4610] loss=0.8720, lr=0.0000122, metrics:accuracy:0.6233
INFO:root:22:13:58 [Epoch 3 Batch 1240/4610] loss=0.8632, lr=0.0000121, metrics:accuracy:0.6228
INFO:root:22:14:01 [Epoch 3 Batch 1280/4610] loss=0.8768, lr=0.0000121, metrics:accuracy:0.6224
INFO:root:22:14:04 [Epoch 3 Batch 1320/4610] loss=0.9025, lr=0.0000121, metrics:accuracy:0.6208
INFO:root:22:14:07 [Epoch 3 Batch 1360/4610] loss=0.8097, lr=0.0000120, metrics:accuracy:0.6220
INFO:root:22:14:10 [Epoch 3 Batch 1400/4610] loss=0.9734, lr=0.0000120, metrics:accuracy:0.6197
INFO:root:22:14:13 [Epoch 3 Batch 1440/4610] loss=0.8143, lr=0.0000119, metrics:accuracy:0.6212
INFO:root:22:14:16 [Epoch 3 Batch 1480/4610] loss=0.9043, lr=0.0000119, metrics:accuracy:0.6196
INFO:root:22:14:19 [Epoch 3 Batch 1520/4610] loss=0.8857, lr=0.0000119, metrics:accuracy:0.6190
INFO:root:22:14:22 [Epoch 3 Batch 1560/4610] loss=0.8859, lr=0.0000118, metrics:accuracy:0.6186
INFO:root:22:14:25 [Epoch 3 Batch 1600/4610] loss=0.8478, lr=0.0000118, metrics:accuracy:0.6187
INFO:root:22:14:28 [Epoch 3 Batch 1640/4610] loss=0.8408, lr=0.0000117, metrics:accuracy:0.6187
INFO:root:22:14:31 [Epoch 3 Batch 1680/4610] loss=0.8171, lr=0.0000117, metrics:accuracy:0.6190
INFO:root:22:14:33 [Epoch 3 Batch 1720/4610] loss=0.8202, lr=0.0000117, metrics:accuracy:0.6192
INFO:root:22:14:37 [Epoch 3 Batch 1760/4610] loss=0.7652, lr=0.0000116, metrics:accuracy:0.6198
INFO:root:22:14:39 [Epoch 3 Batch 1800/4610] loss=0.8504, lr=0.0000116, metrics:accuracy:0.6199
INFO:root:22:14:42 [Epoch 3 Batch 1840/4610] loss=0.8090, lr=0.0000116, metrics:accuracy:0.6202
INFO:root:22:14:45 [Epoch 3 Batch 1880/4610] loss=0.8308, lr=0.0000115, metrics:accuracy:0.6197
INFO:root:22:14:48 [Epoch 3 Batch 1920/4610] loss=0.8859, lr=0.0000115, metrics:accuracy:0.6198
INFO:root:22:14:51 [Epoch 3 Batch 1960/4610] loss=0.7589, lr=0.0000114, metrics:accuracy:0.6208
INFO:root:22:14:54 [Epoch 3 Batch 2000/4610] loss=0.8381, lr=0.0000114, metrics:accuracy:0.6209
INFO:root:22:14:57 [Epoch 3 Batch 2040/4610] loss=0.7557, lr=0.0000114, metrics:accuracy:0.6216
INFO:root:22:15:00 [Epoch 3 Batch 2080/4610] loss=0.8722, lr=0.0000113, metrics:accuracy:0.6211
INFO:root:22:15:03 [Epoch 3 Batch 2120/4610] loss=0.8409, lr=0.0000113, metrics:accuracy:0.6216
INFO:root:22:15:05 [Epoch 3 Batch 2160/4610] loss=0.8316, lr=0.0000112, metrics:accuracy:0.6220
INFO:root:22:15:09 [Epoch 3 Batch 2200/4610] loss=0.7913, lr=0.0000112, metrics:accuracy:0.6223
INFO:root:22:15:11 [Epoch 3 Batch 2240/4610] loss=0.8837, lr=0.0000112, metrics:accuracy:0.6218
INFO:root:22:15:14 [Epoch 3 Batch 2280/4610] loss=0.7492, lr=0.0000111, metrics:accuracy:0.6229
INFO:root:22:15:17 [Epoch 3 Batch 2320/4610] loss=0.8334, lr=0.0000111, metrics:accuracy:0.6227
INFO:root:22:15:20 [Epoch 3 Batch 2360/4610] loss=0.8538, lr=0.0000111, metrics:accuracy:0.6227
INFO:root:22:15:23 [Epoch 3 Batch 2400/4610] loss=0.7555, lr=0.0000110, metrics:accuracy:0.6235
INFO:root:22:15:26 [Epoch 3 Batch 2440/4610] loss=0.8042, lr=0.0000110, metrics:accuracy:0.6233
INFO:root:22:15:29 [Epoch 3 Batch 2480/4610] loss=0.8612, lr=0.0000109, metrics:accuracy:0.6236
INFO:root:22:15:32 [Epoch 3 Batch 2520/4610] loss=0.8786, lr=0.0000109, metrics:accuracy:0.6233
INFO:root:22:15:35 [Epoch 3 Batch 2560/4610] loss=0.7539, lr=0.0000109, metrics:accuracy:0.6234
INFO:root:22:15:38 [Epoch 3 Batch 2600/4610] loss=0.8377, lr=0.0000108, metrics:accuracy:0.6227
INFO:root:22:15:41 [Epoch 3 Batch 2640/4610] loss=0.9004, lr=0.0000108, metrics:accuracy:0.6225
INFO:root:22:15:43 [Epoch 3 Batch 2680/4610] loss=0.8175, lr=0.0000107, metrics:accuracy:0.6227
INFO:root:22:15:46 [Epoch 3 Batch 2720/4610] loss=0.7853, lr=0.0000107, metrics:accuracy:0.6231
INFO:root:22:15:49 [Epoch 3 Batch 2760/4610] loss=0.8284, lr=0.0000107, metrics:accuracy:0.6233
INFO:root:22:15:52 [Epoch 3 Batch 2800/4610] loss=0.7227, lr=0.0000106, metrics:accuracy:0.6238
INFO:root:22:15:55 [Epoch 3 Batch 2840/4610] loss=0.7566, lr=0.0000106, metrics:accuracy:0.6242
INFO:root:22:15:58 [Epoch 3 Batch 2880/4610] loss=0.8383, lr=0.0000106, metrics:accuracy:0.6241
INFO:root:22:16:01 [Epoch 3 Batch 2920/4610] loss=0.7867, lr=0.0000105, metrics:accuracy:0.6244
INFO:root:22:16:04 [Epoch 3 Batch 2960/4610] loss=0.8134, lr=0.0000105, metrics:accuracy:0.6244
INFO:root:22:16:07 [Epoch 3 Batch 3000/4610] loss=0.8424, lr=0.0000104, metrics:accuracy:0.6245
INFO:root:22:16:10 [Epoch 3 Batch 3040/4610] loss=0.7648, lr=0.0000104, metrics:accuracy:0.6250
INFO:root:22:16:13 [Epoch 3 Batch 3080/4610] loss=0.8590, lr=0.0000104, metrics:accuracy:0.6244
INFO:root:22:16:15 [Epoch 3 Batch 3120/4610] loss=0.8607, lr=0.0000103, metrics:accuracy:0.6244
INFO:root:22:16:19 [Epoch 3 Batch 3160/4610] loss=0.8266, lr=0.0000103, metrics:accuracy:0.6240
INFO:root:22:16:21 [Epoch 3 Batch 3200/4610] loss=0.8314, lr=0.0000102, metrics:accuracy:0.6241
INFO:root:22:16:24 [Epoch 3 Batch 3240/4610] loss=0.8520, lr=0.0000102, metrics:accuracy:0.6242
INFO:root:22:16:27 [Epoch 3 Batch 3280/4610] loss=0.8022, lr=0.0000102, metrics:accuracy:0.6243
INFO:root:22:16:30 [Epoch 3 Batch 3320/4610] loss=0.8254, lr=0.0000101, metrics:accuracy:0.6241
INFO:root:22:16:33 [Epoch 3 Batch 3360/4610] loss=0.8155, lr=0.0000101, metrics:accuracy:0.6237
INFO:root:22:16:36 [Epoch 3 Batch 3400/4610] loss=0.8165, lr=0.0000101, metrics:accuracy:0.6238
INFO:root:22:16:39 [Epoch 3 Batch 3440/4610] loss=0.8728, lr=0.0000100, metrics:accuracy:0.6235
INFO:root:22:16:42 [Epoch 3 Batch 3480/4610] loss=0.8561, lr=0.0000100, metrics:accuracy:0.6239
INFO:root:22:16:45 [Epoch 3 Batch 3520/4610] loss=0.9391, lr=0.0000099, metrics:accuracy:0.6232
INFO:root:22:16:48 [Epoch 3 Batch 3560/4610] loss=0.7785, lr=0.0000099, metrics:accuracy:0.6237
INFO:root:22:16:50 [Epoch 3 Batch 3600/4610] loss=0.7653, lr=0.0000099, metrics:accuracy:0.6239
INFO:root:22:16:53 [Epoch 3 Batch 3640/4610] loss=0.8698, lr=0.0000098, metrics:accuracy:0.6240
INFO:root:22:16:56 [Epoch 3 Batch 3680/4610] loss=0.7685, lr=0.0000098, metrics:accuracy:0.6243
INFO:root:22:16:59 [Epoch 3 Batch 3720/4610] loss=0.8703, lr=0.0000097, metrics:accuracy:0.6245
INFO:root:22:17:02 [Epoch 3 Batch 3760/4610] loss=0.8609, lr=0.0000097, metrics:accuracy:0.6245
INFO:root:22:17:05 [Epoch 3 Batch 3800/4610] loss=0.8992, lr=0.0000097, metrics:accuracy:0.6242
INFO:root:22:17:07 [Epoch 3 Batch 3840/4610] loss=0.7868, lr=0.0000096, metrics:accuracy:0.6247
INFO:root:22:17:10 [Epoch 3 Batch 3880/4610] loss=0.8573, lr=0.0000096, metrics:accuracy:0.6247
INFO:root:22:17:13 [Epoch 3 Batch 3920/4610] loss=0.8064, lr=0.0000095, metrics:accuracy:0.6250
INFO:root:22:17:16 [Epoch 3 Batch 3960/4610] loss=0.9243, lr=0.0000095, metrics:accuracy:0.6248
INFO:root:22:17:19 [Epoch 3 Batch 4000/4610] loss=0.8518, lr=0.0000095, metrics:accuracy:0.6244
INFO:root:22:17:22 [Epoch 3 Batch 4040/4610] loss=0.8606, lr=0.0000094, metrics:accuracy:0.6242
INFO:root:22:17:25 [Epoch 3 Batch 4080/4610] loss=0.8202, lr=0.0000094, metrics:accuracy:0.6243
INFO:root:22:17:28 [Epoch 3 Batch 4120/4610] loss=0.7452, lr=0.0000094, metrics:accuracy:0.6249
INFO:root:22:17:30 [Epoch 3 Batch 4160/4610] loss=0.8357, lr=0.0000093, metrics:accuracy:0.6249
INFO:root:22:17:33 [Epoch 3 Batch 4200/4610] loss=0.8637, lr=0.0000093, metrics:accuracy:0.6248
INFO:root:22:17:36 [Epoch 3 Batch 4240/4610] loss=0.8424, lr=0.0000092, metrics:accuracy:0.6247
INFO:root:22:17:39 [Epoch 3 Batch 4280/4610] loss=0.7692, lr=0.0000092, metrics:accuracy:0.6250
INFO:root:22:17:42 [Epoch 3 Batch 4320/4610] loss=0.8263, lr=0.0000092, metrics:accuracy:0.6251
INFO:root:22:17:45 [Epoch 3 Batch 4360/4610] loss=0.8391, lr=0.0000091, metrics:accuracy:0.6250
INFO:root:22:17:48 [Epoch 3 Batch 4400/4610] loss=0.8514, lr=0.0000091, metrics:accuracy:0.6249
INFO:root:22:17:51 [Epoch 3 Batch 4440/4610] loss=0.8761, lr=0.0000090, metrics:accuracy:0.6249
INFO:root:22:17:53 [Epoch 3 Batch 4480/4610] loss=0.8599, lr=0.0000090, metrics:accuracy:0.6248
INFO:root:22:17:57 [Epoch 3 Batch 4520/4610] loss=0.8058, lr=0.0000090, metrics:accuracy:0.6250
INFO:root:22:18:00 [Epoch 3 Batch 4560/4610] loss=0.8450, lr=0.0000089, metrics:accuracy:0.6251
INFO:root:22:18:02 [Epoch 3 Batch 4600/4610] loss=0.8605, lr=0.0000089, metrics:accuracy:0.6252
INFO:root:22:18:03 Now we are doing evaluation on dev with gpu(0).
INFO:root:22:18:04 [Batch 40/618] loss=0.9152, metrics:accuracy:0.5656
INFO:root:22:18:06 [Batch 80/618] loss=1.1004, metrics:accuracy:0.5531
INFO:root:22:18:07 [Batch 120/618] loss=1.0516, metrics:accuracy:0.5448
INFO:root:22:18:08 [Batch 160/618] loss=1.1446, metrics:accuracy:0.5391
INFO:root:22:18:09 [Batch 200/618] loss=0.9890, metrics:accuracy:0.5481
INFO:root:22:18:10 [Batch 240/618] loss=1.0336, metrics:accuracy:0.5490
INFO:root:22:18:11 [Batch 280/618] loss=1.0330, metrics:accuracy:0.5491
INFO:root:22:18:12 [Batch 320/618] loss=1.0639, metrics:accuracy:0.5484
INFO:root:22:18:13 [Batch 360/618] loss=1.0321, metrics:accuracy:0.5531
INFO:root:22:18:15 [Batch 400/618] loss=0.9958, metrics:accuracy:0.5584
INFO:root:22:18:16 [Batch 440/618] loss=0.9310, metrics:accuracy:0.5614
INFO:root:22:18:17 [Batch 480/618] loss=1.0449, metrics:accuracy:0.5620
INFO:root:22:18:18 [Batch 520/618] loss=0.9093, metrics:accuracy:0.5623
INFO:root:22:18:19 [Batch 560/618] loss=1.0202, metrics:accuracy:0.5636
INFO:root:22:18:21 [Batch 600/618] loss=0.9944, metrics:accuracy:0.5648
INFO:root:22:18:21 validation metrics:accuracy:0.5642
INFO:root:22:18:21 Time cost=18.00s, throughput=274.68 samples/s
INFO:root:22:18:22 params saved in: ./output_dir/model_bert_meituan_2.params
INFO:root:22:18:22 Time cost=353.41s
INFO:root:22:18:26 [Epoch 4 Batch 40/4610] loss=0.7241, lr=0.0000088, metrics:accuracy:0.6937
INFO:root:22:18:29 [Epoch 4 Batch 80/4610] loss=0.7576, lr=0.0000088, metrics:accuracy:0.6844
INFO:root:22:18:31 [Epoch 4 Batch 120/4610] loss=0.7706, lr=0.0000088, metrics:accuracy:0.6823
INFO:root:22:18:35 [Epoch 4 Batch 160/4610] loss=0.7498, lr=0.0000087, metrics:accuracy:0.6758
INFO:root:22:18:37 [Epoch 4 Batch 200/4610] loss=0.6523, lr=0.0000087, metrics:accuracy:0.6831
INFO:root:22:18:40 [Epoch 4 Batch 240/4610] loss=0.6641, lr=0.0000087, metrics:accuracy:0.6875
INFO:root:22:18:43 [Epoch 4 Batch 280/4610] loss=0.7288, lr=0.0000086, metrics:accuracy:0.6830
INFO:root:22:18:46 [Epoch 4 Batch 320/4610] loss=0.6674, lr=0.0000086, metrics:accuracy:0.6879
INFO:root:22:18:49 [Epoch 4 Batch 360/4610] loss=0.7357, lr=0.0000085, metrics:accuracy:0.6885
INFO:root:22:18:52 [Epoch 4 Batch 400/4610] loss=0.7187, lr=0.0000085, metrics:accuracy:0.6891
INFO:root:22:18:55 [Epoch 4 Batch 440/4610] loss=0.7965, lr=0.0000085, metrics:accuracy:0.6872
INFO:root:22:18:58 [Epoch 4 Batch 480/4610] loss=0.7659, lr=0.0000084, metrics:accuracy:0.6844
INFO:root:22:19:01 [Epoch 4 Batch 520/4610] loss=0.7188, lr=0.0000084, metrics:accuracy:0.6851
INFO:root:22:19:04 [Epoch 4 Batch 560/4610] loss=0.6997, lr=0.0000083, metrics:accuracy:0.6864
INFO:root:22:19:07 [Epoch 4 Batch 600/4610] loss=0.7544, lr=0.0000083, metrics:accuracy:0.6867
INFO:root:22:19:09 [Epoch 4 Batch 640/4610] loss=0.7330, lr=0.0000083, metrics:accuracy:0.6865
INFO:root:22:19:12 [Epoch 4 Batch 680/4610] loss=0.7018, lr=0.0000082, metrics:accuracy:0.6881
INFO:root:22:19:15 [Epoch 4 Batch 720/4610] loss=0.6821, lr=0.0000082, metrics:accuracy:0.6884
INFO:root:22:19:18 [Epoch 4 Batch 760/4610] loss=0.7804, lr=0.0000082, metrics:accuracy:0.6868
INFO:root:22:19:21 [Epoch 4 Batch 800/4610] loss=0.6983, lr=0.0000081, metrics:accuracy:0.6869
INFO:root:22:19:24 [Epoch 4 Batch 840/4610] loss=0.7923, lr=0.0000081, metrics:accuracy:0.6854
INFO:root:22:19:27 [Epoch 4 Batch 880/4610] loss=0.7150, lr=0.0000080, metrics:accuracy:0.6849
INFO:root:22:19:30 [Epoch 4 Batch 920/4610] loss=0.7226, lr=0.0000080, metrics:accuracy:0.6862
INFO:root:22:19:33 [Epoch 4 Batch 960/4610] loss=0.6851, lr=0.0000080, metrics:accuracy:0.6866
INFO:root:22:19:36 [Epoch 4 Batch 1000/4610] loss=0.6871, lr=0.0000079, metrics:accuracy:0.6880
INFO:root:22:19:38 [Epoch 4 Batch 1040/4610] loss=0.7131, lr=0.0000079, metrics:accuracy:0.6876
INFO:root:22:19:41 [Epoch 4 Batch 1080/4610] loss=0.6532, lr=0.0000078, metrics:accuracy:0.6870
INFO:root:22:19:44 [Epoch 4 Batch 1120/4610] loss=0.7303, lr=0.0000078, metrics:accuracy:0.6877
INFO:root:22:19:47 [Epoch 4 Batch 1160/4610] loss=0.7155, lr=0.0000078, metrics:accuracy:0.6867
INFO:root:22:19:50 [Epoch 4 Batch 1200/4610] loss=0.7135, lr=0.0000077, metrics:accuracy:0.6860
INFO:root:22:19:53 [Epoch 4 Batch 1240/4610] loss=0.6451, lr=0.0000077, metrics:accuracy:0.6883
INFO:root:22:19:56 [Epoch 4 Batch 1280/4610] loss=0.6750, lr=0.0000076, metrics:accuracy:0.6892
INFO:root:22:19:59 [Epoch 4 Batch 1320/4610] loss=0.6668, lr=0.0000076, metrics:accuracy:0.6903
INFO:root:22:20:02 [Epoch 4 Batch 1360/4610] loss=0.6984, lr=0.0000076, metrics:accuracy:0.6903
INFO:root:22:20:05 [Epoch 4 Batch 1400/4610] loss=0.7179, lr=0.0000075, metrics:accuracy:0.6907
INFO:root:22:20:08 [Epoch 4 Batch 1440/4610] loss=0.7474, lr=0.0000075, metrics:accuracy:0.6897
INFO:root:22:20:11 [Epoch 4 Batch 1480/4610] loss=0.7272, lr=0.0000075, metrics:accuracy:0.6898
INFO:root:22:20:14 [Epoch 4 Batch 1520/4610] loss=0.7270, lr=0.0000074, metrics:accuracy:0.6902
INFO:root:22:20:17 [Epoch 4 Batch 1560/4610] loss=0.7546, lr=0.0000074, metrics:accuracy:0.6900
INFO:root:22:20:20 [Epoch 4 Batch 1600/4610] loss=0.7192, lr=0.0000073, metrics:accuracy:0.6903
INFO:root:22:20:23 [Epoch 4 Batch 1640/4610] loss=0.6458, lr=0.0000073, metrics:accuracy:0.6915
INFO:root:22:20:26 [Epoch 4 Batch 1680/4610] loss=0.6162, lr=0.0000073, metrics:accuracy:0.6921
INFO:root:22:20:28 [Epoch 4 Batch 1720/4610] loss=0.7306, lr=0.0000072, metrics:accuracy:0.6918
INFO:root:22:20:32 [Epoch 4 Batch 1760/4610] loss=0.7676, lr=0.0000072, metrics:accuracy:0.6917
INFO:root:22:20:34 [Epoch 4 Batch 1800/4610] loss=0.6008, lr=0.0000071, metrics:accuracy:0.6932
INFO:root:22:20:37 [Epoch 4 Batch 1840/4610] loss=0.7247, lr=0.0000071, metrics:accuracy:0.6927
INFO:root:22:20:40 [Epoch 4 Batch 1880/4610] loss=0.7097, lr=0.0000071, metrics:accuracy:0.6929
INFO:root:22:20:43 [Epoch 4 Batch 1920/4610] loss=0.7384, lr=0.0000070, metrics:accuracy:0.6926
INFO:root:22:20:46 [Epoch 4 Batch 1960/4610] loss=0.6879, lr=0.0000070, metrics:accuracy:0.6920
INFO:root:22:20:49 [Epoch 4 Batch 2000/4610] loss=0.6814, lr=0.0000070, metrics:accuracy:0.6929
INFO:root:22:20:52 [Epoch 4 Batch 2040/4610] loss=0.6648, lr=0.0000069, metrics:accuracy:0.6932
INFO:root:22:20:55 [Epoch 4 Batch 2080/4610] loss=0.7262, lr=0.0000069, metrics:accuracy:0.6931
INFO:root:22:20:57 [Epoch 4 Batch 2120/4610] loss=0.7101, lr=0.0000068, metrics:accuracy:0.6927
INFO:root:22:21:00 [Epoch 4 Batch 2160/4610] loss=0.7098, lr=0.0000068, metrics:accuracy:0.6926
INFO:root:22:21:03 [Epoch 4 Batch 2200/4610] loss=0.6917, lr=0.0000068, metrics:accuracy:0.6930
INFO:root:22:21:06 [Epoch 4 Batch 2240/4610] loss=0.7984, lr=0.0000067, metrics:accuracy:0.6922
INFO:root:22:21:09 [Epoch 4 Batch 2280/4610] loss=0.6871, lr=0.0000067, metrics:accuracy:0.6927
INFO:root:22:21:12 [Epoch 4 Batch 2320/4610] loss=0.7955, lr=0.0000066, metrics:accuracy:0.6922
INFO:root:22:21:14 [Epoch 4 Batch 2360/4610] loss=0.6943, lr=0.0000066, metrics:accuracy:0.6923
INFO:root:22:21:17 [Epoch 4 Batch 2400/4610] loss=0.7108, lr=0.0000066, metrics:accuracy:0.6926
INFO:root:22:21:20 [Epoch 4 Batch 2440/4610] loss=0.6885, lr=0.0000065, metrics:accuracy:0.6928
INFO:root:22:21:23 [Epoch 4 Batch 2480/4610] loss=0.7357, lr=0.0000065, metrics:accuracy:0.6927
INFO:root:22:21:26 [Epoch 4 Batch 2520/4610] loss=0.6967, lr=0.0000065, metrics:accuracy:0.6929
INFO:root:22:21:29 [Epoch 4 Batch 2560/4610] loss=0.7211, lr=0.0000064, metrics:accuracy:0.6930
INFO:root:22:21:32 [Epoch 4 Batch 2600/4610] loss=0.7746, lr=0.0000064, metrics:accuracy:0.6924
INFO:root:22:21:34 [Epoch 4 Batch 2640/4610] loss=0.7161, lr=0.0000063, metrics:accuracy:0.6925
INFO:root:22:21:37 [Epoch 4 Batch 2680/4610] loss=0.6760, lr=0.0000063, metrics:accuracy:0.6925
INFO:root:22:21:40 [Epoch 4 Batch 2720/4610] loss=0.7291, lr=0.0000063, metrics:accuracy:0.6921
INFO:root:22:21:43 [Epoch 4 Batch 2760/4610] loss=0.7191, lr=0.0000062, metrics:accuracy:0.6919
INFO:root:22:21:46 [Epoch 4 Batch 2800/4610] loss=0.6829, lr=0.0000062, metrics:accuracy:0.6924
INFO:root:22:21:49 [Epoch 4 Batch 2840/4610] loss=0.7439, lr=0.0000061, metrics:accuracy:0.6924
INFO:root:22:21:52 [Epoch 4 Batch 2880/4610] loss=0.6965, lr=0.0000061, metrics:accuracy:0.6924
INFO:root:22:21:55 [Epoch 4 Batch 2920/4610] loss=0.7058, lr=0.0000061, metrics:accuracy:0.6924
INFO:root:22:21:57 [Epoch 4 Batch 2960/4610] loss=0.7623, lr=0.0000060, metrics:accuracy:0.6924
INFO:root:22:22:01 [Epoch 4 Batch 3000/4610] loss=0.6733, lr=0.0000060, metrics:accuracy:0.6924
INFO:root:22:22:04 [Epoch 4 Batch 3040/4610] loss=0.7422, lr=0.0000060, metrics:accuracy:0.6925
INFO:root:22:22:06 [Epoch 4 Batch 3080/4610] loss=0.6738, lr=0.0000059, metrics:accuracy:0.6931
INFO:root:22:22:10 [Epoch 4 Batch 3120/4610] loss=0.6975, lr=0.0000059, metrics:accuracy:0.6934
INFO:root:22:22:12 [Epoch 4 Batch 3160/4610] loss=0.6802, lr=0.0000058, metrics:accuracy:0.6938
INFO:root:22:22:15 [Epoch 4 Batch 3200/4610] loss=0.6800, lr=0.0000058, metrics:accuracy:0.6938
INFO:root:22:22:18 [Epoch 4 Batch 3240/4610] loss=0.6918, lr=0.0000058, metrics:accuracy:0.6944
INFO:root:22:22:21 [Epoch 4 Batch 3280/4610] loss=0.6603, lr=0.0000057, metrics:accuracy:0.6948
INFO:root:22:22:24 [Epoch 4 Batch 3320/4610] loss=0.7191, lr=0.0000057, metrics:accuracy:0.6947
INFO:root:22:22:27 [Epoch 4 Batch 3360/4610] loss=0.6909, lr=0.0000056, metrics:accuracy:0.6949
INFO:root:22:22:30 [Epoch 4 Batch 3400/4610] loss=0.7803, lr=0.0000056, metrics:accuracy:0.6949
INFO:root:22:22:33 [Epoch 4 Batch 3440/4610] loss=0.7356, lr=0.0000056, metrics:accuracy:0.6947
INFO:root:22:22:36 [Epoch 4 Batch 3480/4610] loss=0.6937, lr=0.0000055, metrics:accuracy:0.6949
INFO:root:22:22:39 [Epoch 4 Batch 3520/4610] loss=0.7861, lr=0.0000055, metrics:accuracy:0.6947
INFO:root:22:22:42 [Epoch 4 Batch 3560/4610] loss=0.6671, lr=0.0000054, metrics:accuracy:0.6951
INFO:root:22:22:45 [Epoch 4 Batch 3600/4610] loss=0.7703, lr=0.0000054, metrics:accuracy:0.6950
INFO:root:22:22:47 [Epoch 4 Batch 3640/4610] loss=0.7091, lr=0.0000054, metrics:accuracy:0.6950
INFO:root:22:22:51 [Epoch 4 Batch 3680/4610] loss=0.7353, lr=0.0000053, metrics:accuracy:0.6950
INFO:root:22:22:53 [Epoch 4 Batch 3720/4610] loss=0.7023, lr=0.0000053, metrics:accuracy:0.6949
INFO:root:22:22:56 [Epoch 4 Batch 3760/4610] loss=0.7203, lr=0.0000053, metrics:accuracy:0.6947
INFO:root:22:22:59 [Epoch 4 Batch 3800/4610] loss=0.7148, lr=0.0000052, metrics:accuracy:0.6943
INFO:root:22:23:02 [Epoch 4 Batch 3840/4610] loss=0.6936, lr=0.0000052, metrics:accuracy:0.6944
INFO:root:22:23:05 [Epoch 4 Batch 3880/4610] loss=0.6771, lr=0.0000051, metrics:accuracy:0.6950
INFO:root:22:23:08 [Epoch 4 Batch 3920/4610] loss=0.7367, lr=0.0000051, metrics:accuracy:0.6950
INFO:root:22:23:11 [Epoch 4 Batch 3960/4610] loss=0.7238, lr=0.0000051, metrics:accuracy:0.6950
INFO:root:22:23:14 [Epoch 4 Batch 4000/4610] loss=0.7330, lr=0.0000050, metrics:accuracy:0.6951
INFO:root:22:23:17 [Epoch 4 Batch 4040/4610] loss=0.6567, lr=0.0000050, metrics:accuracy:0.6951
INFO:root:22:23:20 [Epoch 4 Batch 4080/4610] loss=0.7159, lr=0.0000049, metrics:accuracy:0.6949
INFO:root:22:23:23 [Epoch 4 Batch 4120/4610] loss=0.6737, lr=0.0000049, metrics:accuracy:0.6949
INFO:root:22:23:26 [Epoch 4 Batch 4160/4610] loss=0.7313, lr=0.0000049, metrics:accuracy:0.6947
INFO:root:22:23:28 [Epoch 4 Batch 4200/4610] loss=0.6544, lr=0.0000048, metrics:accuracy:0.6949
INFO:root:22:23:32 [Epoch 4 Batch 4240/4610] loss=0.7596, lr=0.0000048, metrics:accuracy:0.6945
INFO:root:22:23:34 [Epoch 4 Batch 4280/4610] loss=0.7198, lr=0.0000048, metrics:accuracy:0.6945
INFO:root:22:23:37 [Epoch 4 Batch 4320/4610] loss=0.7012, lr=0.0000047, metrics:accuracy:0.6946
INFO:root:22:23:40 [Epoch 4 Batch 4360/4610] loss=0.6348, lr=0.0000047, metrics:accuracy:0.6947
INFO:root:22:23:43 [Epoch 4 Batch 4400/4610] loss=0.7188, lr=0.0000046, metrics:accuracy:0.6947
INFO:root:22:23:46 [Epoch 4 Batch 4440/4610] loss=0.6722, lr=0.0000046, metrics:accuracy:0.6949
INFO:root:22:23:49 [Epoch 4 Batch 4480/4610] loss=0.6848, lr=0.0000046, metrics:accuracy:0.6951
INFO:root:22:23:52 [Epoch 4 Batch 4520/4610] loss=0.7072, lr=0.0000045, metrics:accuracy:0.6954
INFO:root:22:23:55 [Epoch 4 Batch 4560/4610] loss=0.7231, lr=0.0000045, metrics:accuracy:0.6953
INFO:root:22:23:58 [Epoch 4 Batch 4600/4610] loss=0.6698, lr=0.0000044, metrics:accuracy:0.6954
INFO:root:22:23:59 Now we are doing evaluation on dev with gpu(0).
INFO:root:22:24:00 [Batch 40/618] loss=1.0292, metrics:accuracy:0.5656
INFO:root:22:24:01 [Batch 80/618] loss=1.2089, metrics:accuracy:0.5516
INFO:root:22:24:02 [Batch 120/618] loss=1.1469, metrics:accuracy:0.5406
INFO:root:22:24:03 [Batch 160/618] loss=1.2903, metrics:accuracy:0.5352
INFO:root:22:24:05 [Batch 200/618] loss=1.1376, metrics:accuracy:0.5363
INFO:root:22:24:06 [Batch 240/618] loss=1.1867, metrics:accuracy:0.5318
INFO:root:22:24:07 [Batch 280/618] loss=1.1621, metrics:accuracy:0.5344
INFO:root:22:24:08 [Batch 320/618] loss=1.2136, metrics:accuracy:0.5316
INFO:root:22:24:09 [Batch 360/618] loss=1.1899, metrics:accuracy:0.5361
INFO:root:22:24:10 [Batch 400/618] loss=1.1188, metrics:accuracy:0.5394
INFO:root:22:24:11 [Batch 440/618] loss=1.0200, metrics:accuracy:0.5429
INFO:root:22:24:13 [Batch 480/618] loss=1.1647, metrics:accuracy:0.5430
INFO:root:22:24:14 [Batch 520/618] loss=1.0010, metrics:accuracy:0.5450
INFO:root:22:24:15 [Batch 560/618] loss=1.1445, metrics:accuracy:0.5442
INFO:root:22:24:16 [Batch 600/618] loss=1.1140, metrics:accuracy:0.5442
INFO:root:22:24:16 validation metrics:accuracy:0.5445
INFO:root:22:24:16 Time cost=17.77s, throughput=278.22 samples/s
INFO:root:22:24:18 params saved in: ./output_dir/model_bert_meituan_3.params
INFO:root:22:24:18 Time cost=355.64s
INFO:root:22:24:21 [Epoch 5 Batch 40/4610] loss=0.5916, lr=0.0000044, metrics:accuracy:0.7719
INFO:root:22:24:24 [Epoch 5 Batch 80/4610] loss=0.6699, lr=0.0000044, metrics:accuracy:0.7656
INFO:root:22:24:27 [Epoch 5 Batch 120/4610] loss=0.6787, lr=0.0000043, metrics:accuracy:0.7427
INFO:root:22:24:30 [Epoch 5 Batch 160/4610] loss=0.6366, lr=0.0000043, metrics:accuracy:0.7414
INFO:root:22:24:33 [Epoch 5 Batch 200/4610] loss=0.6883, lr=0.0000042, metrics:accuracy:0.7394
INFO:root:22:24:36 [Epoch 5 Batch 240/4610] loss=0.6571, lr=0.0000042, metrics:accuracy:0.7417
INFO:root:22:24:38 [Epoch 5 Batch 280/4610] loss=0.6083, lr=0.0000042, metrics:accuracy:0.7438
INFO:root:22:24:42 [Epoch 5 Batch 320/4610] loss=0.6043, lr=0.0000041, metrics:accuracy:0.7469
INFO:root:22:24:44 [Epoch 5 Batch 360/4610] loss=0.5954, lr=0.0000041, metrics:accuracy:0.7497
INFO:root:22:24:47 [Epoch 5 Batch 400/4610] loss=0.6354, lr=0.0000041, metrics:accuracy:0.7469
INFO:root:22:24:50 [Epoch 5 Batch 440/4610] loss=0.5690, lr=0.0000040, metrics:accuracy:0.7479
INFO:root:22:24:53 [Epoch 5 Batch 480/4610] loss=0.6182, lr=0.0000040, metrics:accuracy:0.7502
INFO:root:22:24:56 [Epoch 5 Batch 520/4610] loss=0.6154, lr=0.0000039, metrics:accuracy:0.7509
INFO:root:22:24:59 [Epoch 5 Batch 560/4610] loss=0.5662, lr=0.0000039, metrics:accuracy:0.7499
INFO:root:22:25:01 [Epoch 5 Batch 600/4610] loss=0.5662, lr=0.0000039, metrics:accuracy:0.7508
INFO:root:22:25:04 [Epoch 5 Batch 640/4610] loss=0.5603, lr=0.0000038, metrics:accuracy:0.7519
INFO:root:22:25:07 [Epoch 5 Batch 680/4610] loss=0.6514, lr=0.0000038, metrics:accuracy:0.7494
INFO:root:22:25:10 [Epoch 5 Batch 720/4610] loss=0.5662, lr=0.0000037, metrics:accuracy:0.7512
INFO:root:22:25:13 [Epoch 5 Batch 760/4610] loss=0.6233, lr=0.0000037, metrics:accuracy:0.7505
INFO:root:22:25:16 [Epoch 5 Batch 800/4610] loss=0.5718, lr=0.0000037, metrics:accuracy:0.7506
INFO:root:22:25:19 [Epoch 5 Batch 840/4610] loss=0.5187, lr=0.0000036, metrics:accuracy:0.7525
INFO:root:22:25:21 [Epoch 5 Batch 880/4610] loss=0.5726, lr=0.0000036, metrics:accuracy:0.7534
INFO:root:22:25:24 [Epoch 5 Batch 920/4610] loss=0.6159, lr=0.0000036, metrics:accuracy:0.7536
INFO:root:22:25:27 [Epoch 5 Batch 960/4610] loss=0.6306, lr=0.0000035, metrics:accuracy:0.7531
INFO:root:22:25:30 [Epoch 5 Batch 1000/4610] loss=0.5686, lr=0.0000035, metrics:accuracy:0.7536
INFO:root:22:25:33 [Epoch 5 Batch 1040/4610] loss=0.6292, lr=0.0000034, metrics:accuracy:0.7533
INFO:root:22:25:36 [Epoch 5 Batch 1080/4610] loss=0.6189, lr=0.0000034, metrics:accuracy:0.7525
INFO:root:22:25:39 [Epoch 5 Batch 1120/4610] loss=0.5862, lr=0.0000034, metrics:accuracy:0.7527
INFO:root:22:25:41 [Epoch 5 Batch 1160/4610] loss=0.6443, lr=0.0000033, metrics:accuracy:0.7519
INFO:root:22:25:44 [Epoch 5 Batch 1200/4610] loss=0.5937, lr=0.0000033, metrics:accuracy:0.7527
INFO:root:22:25:47 [Epoch 5 Batch 1240/4610] loss=0.6222, lr=0.0000032, metrics:accuracy:0.7524
INFO:root:22:25:50 [Epoch 5 Batch 1280/4610] loss=0.5608, lr=0.0000032, metrics:accuracy:0.7525
INFO:root:22:25:52 [Epoch 5 Batch 1320/4610] loss=0.6822, lr=0.0000032, metrics:accuracy:0.7516
INFO:root:22:25:56 [Epoch 5 Batch 1360/4610] loss=0.6637, lr=0.0000031, metrics:accuracy:0.7504
INFO:root:22:25:58 [Epoch 5 Batch 1400/4610] loss=0.6454, lr=0.0000031, metrics:accuracy:0.7500
INFO:root:22:26:01 [Epoch 5 Batch 1440/4610] loss=0.6337, lr=0.0000030, metrics:accuracy:0.7502
INFO:root:22:26:04 [Epoch 5 Batch 1480/4610] loss=0.5997, lr=0.0000030, metrics:accuracy:0.7499
INFO:root:22:26:07 [Epoch 5 Batch 1520/4610] loss=0.6478, lr=0.0000030, metrics:accuracy:0.7491
INFO:root:22:26:10 [Epoch 5 Batch 1560/4610] loss=0.5933, lr=0.0000029, metrics:accuracy:0.7493
INFO:root:22:26:13 [Epoch 5 Batch 1600/4610] loss=0.5872, lr=0.0000029, metrics:accuracy:0.7490
INFO:root:22:26:16 [Epoch 5 Batch 1640/4610] loss=0.5910, lr=0.0000029, metrics:accuracy:0.7490
INFO:root:22:26:19 [Epoch 5 Batch 1680/4610] loss=0.5893, lr=0.0000028, metrics:accuracy:0.7489
INFO:root:22:26:22 [Epoch 5 Batch 1720/4610] loss=0.6418, lr=0.0000028, metrics:accuracy:0.7483
INFO:root:22:26:25 [Epoch 5 Batch 1760/4610] loss=0.6165, lr=0.0000027, metrics:accuracy:0.7484
INFO:root:22:26:28 [Epoch 5 Batch 1800/4610] loss=0.6002, lr=0.0000027, metrics:accuracy:0.7485
INFO:root:22:26:31 [Epoch 5 Batch 1840/4610] loss=0.5780, lr=0.0000027, metrics:accuracy:0.7488
INFO:root:22:26:34 [Epoch 5 Batch 1880/4610] loss=0.6278, lr=0.0000026, metrics:accuracy:0.7486
INFO:root:22:26:37 [Epoch 5 Batch 1920/4610] loss=0.5437, lr=0.0000026, metrics:accuracy:0.7498
INFO:root:22:26:39 [Epoch 5 Batch 1960/4610] loss=0.6191, lr=0.0000025, metrics:accuracy:0.7498
INFO:root:22:26:42 [Epoch 5 Batch 2000/4610] loss=0.6416, lr=0.0000025, metrics:accuracy:0.7493
INFO:root:22:26:45 [Epoch 5 Batch 2040/4610] loss=0.5653, lr=0.0000025, metrics:accuracy:0.7492
INFO:root:22:26:48 [Epoch 5 Batch 2080/4610] loss=0.6395, lr=0.0000024, metrics:accuracy:0.7488
INFO:root:22:26:51 [Epoch 5 Batch 2120/4610] loss=0.6201, lr=0.0000024, metrics:accuracy:0.7484
INFO:root:22:26:54 [Epoch 5 Batch 2160/4610] loss=0.6365, lr=0.0000024, metrics:accuracy:0.7478
INFO:root:22:26:57 [Epoch 5 Batch 2200/4610] loss=0.6066, lr=0.0000023, metrics:accuracy:0.7475
INFO:root:22:27:00 [Epoch 5 Batch 2240/4610] loss=0.6073, lr=0.0000023, metrics:accuracy:0.7480
INFO:root:22:27:03 [Epoch 5 Batch 2280/4610] loss=0.5563, lr=0.0000022, metrics:accuracy:0.7486
INFO:root:22:27:06 [Epoch 5 Batch 2320/4610] loss=0.5868, lr=0.0000022, metrics:accuracy:0.7493
INFO:root:22:27:09 [Epoch 5 Batch 2360/4610] loss=0.6270, lr=0.0000022, metrics:accuracy:0.7491
INFO:root:22:27:12 [Epoch 5 Batch 2400/4610] loss=0.6012, lr=0.0000021, metrics:accuracy:0.7494
INFO:root:22:27:15 [Epoch 5 Batch 2440/4610] loss=0.5545, lr=0.0000021, metrics:accuracy:0.7490
INFO:root:22:27:18 [Epoch 5 Batch 2480/4610] loss=0.6156, lr=0.0000020, metrics:accuracy:0.7489
INFO:root:22:27:21 [Epoch 5 Batch 2520/4610] loss=0.6245, lr=0.0000020, metrics:accuracy:0.7488
INFO:root:22:27:24 [Epoch 5 Batch 2560/4610] loss=0.5999, lr=0.0000020, metrics:accuracy:0.7489
INFO:root:22:27:27 [Epoch 5 Batch 2600/4610] loss=0.5845, lr=0.0000019, metrics:accuracy:0.7489
INFO:root:22:27:29 [Epoch 5 Batch 2640/4610] loss=0.6800, lr=0.0000019, metrics:accuracy:0.7486
INFO:root:22:27:33 [Epoch 5 Batch 2680/4610] loss=0.6441, lr=0.0000019, metrics:accuracy:0.7483
INFO:root:22:27:35 [Epoch 5 Batch 2720/4610] loss=0.6132, lr=0.0000018, metrics:accuracy:0.7485
INFO:root:22:27:38 [Epoch 5 Batch 2760/4610] loss=0.5975, lr=0.0000018, metrics:accuracy:0.7482
INFO:root:22:27:41 [Epoch 5 Batch 2800/4610] loss=0.5713, lr=0.0000017, metrics:accuracy:0.7484
INFO:root:22:27:44 [Epoch 5 Batch 2840/4610] loss=0.6346, lr=0.0000017, metrics:accuracy:0.7481
INFO:root:22:27:47 [Epoch 5 Batch 2880/4610] loss=0.6195, lr=0.0000017, metrics:accuracy:0.7478
INFO:root:22:27:50 [Epoch 5 Batch 2920/4610] loss=0.6322, lr=0.0000016, metrics:accuracy:0.7477
INFO:root:22:27:53 [Epoch 5 Batch 2960/4610] loss=0.6274, lr=0.0000016, metrics:accuracy:0.7475
INFO:root:22:27:56 [Epoch 5 Batch 3000/4610] loss=0.6298, lr=0.0000015, metrics:accuracy:0.7474
INFO:root:22:27:59 [Epoch 5 Batch 3040/4610] loss=0.6168, lr=0.0000015, metrics:accuracy:0.7474
INFO:root:22:28:02 [Epoch 5 Batch 3080/4610] loss=0.6124, lr=0.0000015, metrics:accuracy:0.7477
INFO:root:22:28:05 [Epoch 5 Batch 3120/4610] loss=0.6398, lr=0.0000014, metrics:accuracy:0.7475
INFO:root:22:28:08 [Epoch 5 Batch 3160/4610] loss=0.6695, lr=0.0000014, metrics:accuracy:0.7468
INFO:root:22:28:11 [Epoch 5 Batch 3200/4610] loss=0.6137, lr=0.0000014, metrics:accuracy:0.7470
INFO:root:22:28:14 [Epoch 5 Batch 3240/4610] loss=0.6030, lr=0.0000013, metrics:accuracy:0.7468
INFO:root:22:28:16 [Epoch 5 Batch 3280/4610] loss=0.5867, lr=0.0000013, metrics:accuracy:0.7470
INFO:root:22:28:19 [Epoch 5 Batch 3320/4610] loss=0.6048, lr=0.0000012, metrics:accuracy:0.7471
INFO:root:22:28:22 [Epoch 5 Batch 3360/4610] loss=0.6052, lr=0.0000012, metrics:accuracy:0.7470
INFO:root:22:28:25 [Epoch 5 Batch 3400/4610] loss=0.6102, lr=0.0000012, metrics:accuracy:0.7468
INFO:root:22:28:28 [Epoch 5 Batch 3440/4610] loss=0.6701, lr=0.0000011, metrics:accuracy:0.7468
INFO:root:22:28:31 [Epoch 5 Batch 3480/4610] loss=0.6141, lr=0.0000011, metrics:accuracy:0.7470
INFO:root:22:28:34 [Epoch 5 Batch 3520/4610] loss=0.5788, lr=0.0000010, metrics:accuracy:0.7471
INFO:root:22:28:37 [Epoch 5 Batch 3560/4610] loss=0.6396, lr=0.0000010, metrics:accuracy:0.7471
INFO:root:22:28:40 [Epoch 5 Batch 3600/4610] loss=0.6278, lr=0.0000010, metrics:accuracy:0.7470
INFO:root:22:28:43 [Epoch 5 Batch 3640/4610] loss=0.6316, lr=0.0000009, metrics:accuracy:0.7466
INFO:root:22:28:46 [Epoch 5 Batch 3680/4610] loss=0.6686, lr=0.0000009, metrics:accuracy:0.7460
INFO:root:22:28:49 [Epoch 5 Batch 3720/4610] loss=0.6157, lr=0.0000008, metrics:accuracy:0.7461
INFO:root:22:28:52 [Epoch 5 Batch 3760/4610] loss=0.5699, lr=0.0000008, metrics:accuracy:0.7462
INFO:root:22:28:55 [Epoch 5 Batch 3800/4610] loss=0.6458, lr=0.0000008, metrics:accuracy:0.7460
INFO:root:22:28:57 [Epoch 5 Batch 3840/4610] loss=0.5733, lr=0.0000007, metrics:accuracy:0.7463
INFO:root:22:29:00 [Epoch 5 Batch 3880/4610] loss=0.6465, lr=0.0000007, metrics:accuracy:0.7462
INFO:root:22:29:03 [Epoch 5 Batch 3920/4610] loss=0.6376, lr=0.0000007, metrics:accuracy:0.7463
INFO:root:22:29:06 [Epoch 5 Batch 3960/4610] loss=0.6140, lr=0.0000006, metrics:accuracy:0.7462
INFO:root:22:29:09 [Epoch 5 Batch 4000/4610] loss=0.6049, lr=0.0000006, metrics:accuracy:0.7463
INFO:root:22:29:12 [Epoch 5 Batch 4040/4610] loss=0.6775, lr=0.0000005, metrics:accuracy:0.7459
INFO:root:22:29:15 [Epoch 5 Batch 4080/4610] loss=0.5735, lr=0.0000005, metrics:accuracy:0.7458
INFO:root:22:29:17 [Epoch 5 Batch 4120/4610] loss=0.6937, lr=0.0000005, metrics:accuracy:0.7454
INFO:root:22:29:20 [Epoch 5 Batch 4160/4610] loss=0.5812, lr=0.0000004, metrics:accuracy:0.7457
INFO:root:22:29:23 [Epoch 5 Batch 4200/4610] loss=0.6123, lr=0.0000004, metrics:accuracy:0.7458
INFO:root:22:29:26 [Epoch 5 Batch 4240/4610] loss=0.5637, lr=0.0000003, metrics:accuracy:0.7463
INFO:root:22:29:29 [Epoch 5 Batch 4280/4610] loss=0.6339, lr=0.0000003, metrics:accuracy:0.7460
INFO:root:22:29:32 [Epoch 5 Batch 4320/4610] loss=0.5472, lr=0.0000003, metrics:accuracy:0.7463
INFO:root:22:29:35 [Epoch 5 Batch 4360/4610] loss=0.6210, lr=0.0000002, metrics:accuracy:0.7465
INFO:root:22:29:38 [Epoch 5 Batch 4400/4610] loss=0.6038, lr=0.0000002, metrics:accuracy:0.7464
INFO:root:22:29:40 [Epoch 5 Batch 4440/4610] loss=0.6285, lr=0.0000002, metrics:accuracy:0.7465
INFO:root:22:29:43 [Epoch 5 Batch 4480/4610] loss=0.5816, lr=0.0000001, metrics:accuracy:0.7467
INFO:root:22:29:46 [Epoch 5 Batch 4520/4610] loss=0.6493, lr=0.0000001, metrics:accuracy:0.7466
INFO:root:22:29:49 [Epoch 5 Batch 4560/4610] loss=0.6575, lr=0.0000000, metrics:accuracy:0.7465
INFO:root:22:29:51 Finish training step: 5757
INFO:root:22:29:51 Now we are doing evaluation on dev with gpu(0).
INFO:root:22:29:52 [Batch 40/618] loss=1.0876, metrics:accuracy:0.5531
INFO:root:22:29:54 [Batch 80/618] loss=1.2646, metrics:accuracy:0.5484
INFO:root:22:29:55 [Batch 120/618] loss=1.1742, metrics:accuracy:0.5458
INFO:root:22:29:56 [Batch 160/618] loss=1.3598, metrics:accuracy:0.5312
INFO:root:22:29:57 [Batch 200/618] loss=1.1882, metrics:accuracy:0.5350
INFO:root:22:29:58 [Batch 240/618] loss=1.2512, metrics:accuracy:0.5286
INFO:root:22:29:59 [Batch 280/618] loss=1.2434, metrics:accuracy:0.5308
INFO:root:22:30:01 [Batch 320/618] loss=1.2609, metrics:accuracy:0.5281
INFO:root:22:30:02 [Batch 360/618] loss=1.2431, metrics:accuracy:0.5299
INFO:root:22:30:03 [Batch 400/618] loss=1.1695, metrics:accuracy:0.5337
INFO:root:22:30:04 [Batch 440/618] loss=1.0696, metrics:accuracy:0.5364
INFO:root:22:30:05 [Batch 480/618] loss=1.2626, metrics:accuracy:0.5357
INFO:root:22:30:06 [Batch 520/618] loss=1.0512, metrics:accuracy:0.5397
INFO:root:22:30:08 [Batch 560/618] loss=1.1946, metrics:accuracy:0.5408
INFO:root:22:30:09 [Batch 600/618] loss=1.1552, metrics:accuracy:0.5408
INFO:root:22:30:09 validation metrics:accuracy:0.5417
INFO:root:22:30:09 Time cost=18.05s, throughput=273.91 samples/s
INFO:root:22:30:11 params saved in: ./output_dir/model_bert_meituan_4.params
INFO:root:22:30:11 Time cost=352.80s
INFO:root:22:30:11 Best model at epoch 2. Validation metrics:accuracy:0.56.42
INFO:root:22:30:11 Now we are doing testing on test with gpu(0).
INFO:root:22:30:29 Time cost=17.78s, throughput=278.12 samples/s
